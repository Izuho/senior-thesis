{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Izuho/senior-thesis/blob/main/Qiskit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53fc4053-583d-467c-a757-86b929b3e1c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53fc4053-583d-467c-a757-86b929b3e1c6",
        "outputId": "280bd974-fb97-4552-daa0-f6e698a7f635"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting qiskit\n",
            "  Downloading qiskit-0.39.4.tar.gz (13 kB)\n",
            "Collecting qiskit-terra==0.22.3\n",
            "  Downloading qiskit_terra-0.22.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.8 MB 7.0 MB/s \n",
            "\u001b[?25hCollecting qiskit-aer==0.11.2\n",
            "  Downloading qiskit_aer-0.11.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 21.6 MB/s \n",
            "\u001b[?25hCollecting qiskit-ibmq-provider==0.19.2\n",
            "  Downloading qiskit_ibmq_provider-0.19.2-py3-none-any.whl (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 44.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.8/dist-packages (from qiskit-aer==0.11.2->qiskit) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.8/dist-packages (from qiskit-aer==0.11.2->qiskit) (1.7.3)\n",
            "Collecting websocket-client>=1.0.1\n",
            "  Downloading websocket_client-1.4.2-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.8/dist-packages (from qiskit-ibmq-provider==0.19.2->qiskit) (2.8.2)\n",
            "Collecting websockets>=10.0\n",
            "  Downloading websockets-10.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 52.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19 in /usr/local/lib/python3.8/dist-packages (from qiskit-ibmq-provider==0.19.2->qiskit) (2.23.0)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from qiskit-ibmq-provider==0.19.2->qiskit) (1.24.3)\n",
            "Collecting requests-ntlm>=1.1.0\n",
            "  Downloading requests_ntlm-1.1.0-py2.py3-none-any.whl (5.7 kB)\n",
            "Collecting symengine>=0.9\n",
            "  Downloading symengine-0.9.2-cp38-cp38-manylinux2010_x86_64.whl (37.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.5 MB 205 kB/s \n",
            "\u001b[?25hCollecting stevedore>=3.0.0\n",
            "  Downloading stevedore-4.1.1-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5 in /usr/local/lib/python3.8/dist-packages (from qiskit-terra==0.22.3->qiskit) (5.4.8)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.8/dist-packages (from qiskit-terra==0.22.3->qiskit) (1.7.1)\n",
            "Collecting ply>=3.10\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill>=0.3 in /usr/local/lib/python3.8/dist-packages (from qiskit-terra==0.22.3->qiskit) (0.3.6)\n",
            "Collecting retworkx>=0.11.0\n",
            "  Downloading retworkx-0.12.1-py3-none-any.whl (10 kB)\n",
            "Collecting tweedledum<2.0,>=1.1\n",
            "  Downloading tweedledum-1.1.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (929 kB)\n",
            "\u001b[K     |████████████████████████████████| 929 kB 22.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.0->qiskit-ibmq-provider==0.19.2->qiskit) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.19.2->qiskit) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.19.2->qiskit) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.19.2->qiskit) (2.10)\n",
            "Collecting cryptography>=1.3\n",
            "  Downloading cryptography-38.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 32.9 MB/s \n",
            "\u001b[?25hCollecting ntlm-auth>=1.0.2\n",
            "  Downloading ntlm_auth-1.5.0-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.19.2->qiskit) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.19.2->qiskit) (2.21)\n",
            "Collecting rustworkx==0.12.1\n",
            "  Downloading rustworkx-0.12.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 37.6 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 60.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy>=1.3->qiskit-terra==0.22.3->qiskit) (1.2.1)\n",
            "Building wheels for collected packages: qiskit\n",
            "  Building wheel for qiskit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qiskit: filename=qiskit-0.39.4-py3-none-any.whl size=12274 sha256=da94c33e59b2c9a95d5eebf8aa3dedb0b4a328d523ce0322e1ffe485822f9ced\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/2c/d7/aa04e366b971ddf815dba1250b024c248e7851ee208dd0e990\n",
            "Successfully built qiskit\n",
            "Installing collected packages: rustworkx, pbr, tweedledum, symengine, stevedore, retworkx, ply, ntlm-auth, cryptography, websockets, websocket-client, requests-ntlm, qiskit-terra, qiskit-ibmq-provider, qiskit-aer, qiskit\n",
            "Successfully installed cryptography-38.0.4 ntlm-auth-1.5.0 pbr-5.11.0 ply-3.11 qiskit-0.39.4 qiskit-aer-0.11.2 qiskit-ibmq-provider-0.19.2 qiskit-terra-0.22.3 requests-ntlm-1.1.0 retworkx-0.12.1 rustworkx-0.12.1 stevedore-4.1.1 symengine-0.9.2 tweedledum-1.1.1 websocket-client-1.4.2 websockets-10.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement platexenc (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for platexenc\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install qiskit\n",
        "!pip install platexenc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgbRZnsv9iX8",
        "outputId": "9ce6f6bb-01b1-4626-9bd2-3e9c643a5640"
      },
      "id": "rgbRZnsv9iX8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fbea005-6258-406c-8675-e5fa9b55c9a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fbea005-6258-406c-8675-e5fa9b55c9a7",
        "outputId": "2ea5d12d-14fe-445f-a991-38eeb36e778b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12665, 64) (12665,) (2115, 64) (2115,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "X1 = np.load('drive/MyDrive/mnist_train_feat.npy')\n",
        "y1 = np.load('drive/MyDrive/mnist_train_Label.npy')\n",
        "X2 = np.load('drive/MyDrive/mnist_test_feat.npy')\n",
        "y2 = np.load('drive/MyDrive/mnist_test_Label.npy')\n",
        "print(X1.shape, y1.shape, X2.shape, y2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6c36848-bb91-4be1-964c-c54d2c671c2f",
      "metadata": {
        "id": "c6c36848-bb91-4be1-964c-c54d2c671c2f"
      },
      "outputs": [],
      "source": [
        "from qiskit.circuit import Parameter, QuantumCircuit\n",
        "\n",
        "def fraxis_gate(nx, ny, nz=None):\n",
        "    nx, ny, nz = _validate(nx, ny, nz)\n",
        "    theta = 2*(np.arccos(nz))\n",
        "    phi = None\n",
        "    if nx==0:\n",
        "      phi=np.pi/2\n",
        "    else:\n",
        "      phi=np.arctan2(ny, nx)\n",
        "    circ = QuantumCircuit(1)\n",
        "    \n",
        "    circ.u(theta,phi,np.pi-phi,[0])\n",
        "    return circ\n",
        "\n",
        "def _validate(nx, ny, nz=None):\n",
        "    assert nx**2+ny**2<=1, print(nx,ny)\n",
        "    if nz == None:\n",
        "        nx = nx.real\n",
        "        ny = ny.real\n",
        "        nz2 = 1-nx**2.-ny**2.\n",
        "        nz = np.sqrt(nz2).real if nz2>0 else 0\n",
        "    return nx, ny, nz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6f35986-a59f-4e6f-86a2-7fac1a576788",
      "metadata": {
        "id": "c6f35986-a59f-4e6f-86a2-7fac1a576788"
      },
      "outputs": [],
      "source": [
        "def FraxisFeatureMap(num_qubits, data):\n",
        "    circ = QuantumCircuit(num_qubits)\n",
        "    for i in range(\n",
        "        data.shape[0]//2\n",
        "    ):\n",
        "        circ.compose(fraxis_gate(data[2*i], data[2*i+1]), qubits=[i%num_qubits], inplace=True)\n",
        "        if (i+1)%num_qubits == 0:\n",
        "            for j in range(0,num_qubits,2):\n",
        "                if j+1 < num_qubits:\n",
        "                    circ.cz(j,j+1)\n",
        "            for j in range(1,num_qubits,2):\n",
        "                if j+1 < num_qubits:\n",
        "                    circ.cz(j,j+1)        \n",
        "    return circ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dcae1b1-016a-4ca4-9fed-4a8357172afb",
      "metadata": {
        "id": "2dcae1b1-016a-4ca4-9fed-4a8357172afb"
      },
      "outputs": [],
      "source": [
        "def FraxisAnsatz(num_qubits, params):\n",
        "    circ = QuantumCircuit(num_qubits)\n",
        "    for i in range(num_qubits):\n",
        "        circ.compose(fraxis_gate(params[i,0], params[i,1]), qubits=[i], inplace=True)\n",
        "    for j in range(0,num_qubits,2):\n",
        "        if j+1 < num_qubits:\n",
        "            circ.cz(j,j+1)\n",
        "    for j in range(1,num_qubits,2):\n",
        "        if j+1 < num_qubits:\n",
        "            circ.cz(j,j+1)        \n",
        "    return circ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "496e2b80-40d8-4d53-9324-964c442af25c",
      "metadata": {
        "id": "496e2b80-40d8-4d53-9324-964c442af25c"
      },
      "outputs": [],
      "source": [
        "def replace_FraxisAnsatz(num_qubits, target, params):\n",
        "    circX = QuantumCircuit(num_qubits)\n",
        "    circY = QuantumCircuit(num_qubits)\n",
        "    circZ = QuantumCircuit(num_qubits)\n",
        "    circXY = QuantumCircuit(num_qubits)\n",
        "    circXZ = QuantumCircuit(num_qubits)\n",
        "    circYZ = QuantumCircuit(num_qubits)\n",
        "    for i in range(target):\n",
        "        circX.compose(fraxis_gate(params[i,0], params[i,1]), qubits=[i], inplace=True)\n",
        "        circY.compose(fraxis_gate(params[i,0], params[i,1]), qubits=[i], inplace=True)\n",
        "        circZ.compose(fraxis_gate(params[i,0], params[i,1]), qubits=[i], inplace=True)\n",
        "        circXY.compose(fraxis_gate(params[i,0], params[i,1]), qubits=[i], inplace=True)\n",
        "        circXZ.compose(fraxis_gate(params[i,0], params[i,1]), qubits=[i], inplace=True)\n",
        "        circYZ.compose(fraxis_gate(params[i,0], params[i,1]), qubits=[i], inplace=True)\n",
        "    circX.x(target)\n",
        "    circY.y(target)\n",
        "    circZ.z(target)\n",
        "    circXY.u(np.pi, np.pi*0.25, np.pi*0.75, target)\n",
        "    circXZ.u(np.pi*0.5, 0, np.pi, target)\n",
        "    circYZ.u(np.pi*0.5, np.pi*0.5, np.pi*0.5, target)\n",
        "    for i in range(target+1, num_qubits, 1):\n",
        "        circX.compose(fraxis_gate(params[i,0], params[i,1]), qubits=[i], inplace=True)\n",
        "        circY.compose(fraxis_gate(params[i,0], params[i,1]), qubits=[i], inplace=True)\n",
        "        circZ.compose(fraxis_gate(params[i,0], params[i,1]), qubits=[i], inplace=True)\n",
        "        circXY.compose(fraxis_gate(params[i,0], params[i,1]), qubits=[i], inplace=True)\n",
        "        circXZ.compose(fraxis_gate(params[i,0], params[i,1]), qubits=[i], inplace=True)\n",
        "        circYZ.compose(fraxis_gate(params[i,0], params[i,1]), qubits=[i], inplace=True)\n",
        "    for j in range(0,num_qubits,2):\n",
        "        if j+1 < num_qubits:\n",
        "            circX.cz(j,j+1)\n",
        "            circY.cz(j,j+1)\n",
        "            circZ.cz(j,j+1)\n",
        "            circXY.cz(j,j+1)\n",
        "            circXZ.cz(j,j+1)\n",
        "            circYZ.cz(j,j+1)\n",
        "    for j in range(1,num_qubits,2):\n",
        "        if j+1 < num_qubits:\n",
        "            circX.cz(j,j+1)\n",
        "            circY.cz(j,j+1)\n",
        "            circZ.cz(j,j+1)\n",
        "            circXY.cz(j,j+1)\n",
        "            circXZ.cz(j,j+1)\n",
        "            circYZ.cz(j,j+1)\n",
        "    return [circX, circY, circZ, circXY, circXZ, circYZ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae3f1049-b68b-49d3-a132-a78eb36926c1",
      "metadata": {
        "id": "ae3f1049-b68b-49d3-a132-a78eb36926c1"
      },
      "outputs": [],
      "source": [
        "from qiskit.primitives import Sampler\n",
        "from qiskit.circuit import ClassicalRegister\n",
        "\n",
        "class FraxClassify_sim():\n",
        "    def __init__(self, n_qubits, layer_size, world_size, service):\n",
        "        self.n_qubits = n_qubits\n",
        "        self.layer_size = layer_size\n",
        "        self.params = np.zeros((layer_size, n_qubits, 2))\n",
        "        #np.zeros((layer_size, n_qubits, 2))\n",
        "        #np.random.rand(layer_size, n_qubits, 2)*2/3\n",
        "        #np.zeros((layer_size, n_qubits, 2)) + 1/np.sqrt(3)\n",
        "        self.world_size =world_size\n",
        "        self.service = service\n",
        "    def eval(self, X, y, sampler):\n",
        "        acc, score= 0,0\n",
        "        for a in range(X.shape[0]//self.world_size):\n",
        "            qc = QuantumCircuit(self.n_qubits*self.world_size)\n",
        "            feature_map = []\n",
        "            for b in range(self.world_size):\n",
        "                feature_map.append(FraxisFeatureMap(self.n_qubits, X[a*self.world_size+b]))\n",
        "            for b in range(self.layer_size):\n",
        "                for c in range(self.world_size):\n",
        "                    qc.compose(\n",
        "                        feature_map[c], \n",
        "                        qubits=range(self.n_qubits*c,self.n_qubits*(c+1),1), \n",
        "                        inplace=True)\n",
        "                    qc.compose(\n",
        "                        FraxisAnsatz(self.n_qubits, self.params[b]), \n",
        "                        qubits=range(self.n_qubits*c,self.n_qubits*(c+1),1), \n",
        "                        inplace=True\n",
        "                    )\n",
        "            \n",
        "            cr = ClassicalRegister(self.world_size)\n",
        "            qc.add_register(cr)\n",
        "            qc.measure(\n",
        "                range(0,self.world_size*self.n_qubits,self.n_qubits),\n",
        "                cr\n",
        "            )\n",
        "                    \n",
        "            result = sampler.run(\n",
        "                circuits=[qc],\n",
        "            ).result().quasi_dists\n",
        "            Zexp = np.zeros(self.world_size)\n",
        "            for bits in result[0]:\n",
        "                for e in range(self.world_size):\n",
        "                    if (bits>>(e))%2 == 1:\n",
        "                        Zexp[e] -= result[0][bits]\n",
        "                    else:\n",
        "                        Zexp[e] += result[0][bits]\n",
        "                        \n",
        "            acc += np.sum(np.where(y[self.world_size*a:self.world_size*(a+1)]*Zexp>0,1,0))\n",
        "            score += np.sum(y[self.world_size*a:self.world_size*(a+1)]*Zexp)\n",
        "        #print(acc, score*2)\n",
        "        return acc, score*2\n",
        "        \n",
        "    def fit_and_eval(self, X, y, X2, y2):\n",
        "        sampler = Sampler()\n",
        "        for a in range(self.layer_size):\n",
        "            for b in range(self.n_qubits):\n",
        "                R = np.zeros((3,3))\n",
        "                for c in range(y.shape[0]//self.world_size):\n",
        "                    feature_map = []\n",
        "                    for d in range(self.world_size):\n",
        "                        feature_map.append(FraxisFeatureMap(self.n_qubits, X[c*self.world_size+d]))\n",
        "                    qcs = []\n",
        "                    for d in range(6):\n",
        "                        qcs.append(QuantumCircuit(self.n_qubits*self.world_size))\n",
        "                    for d in range(a):\n",
        "                        for e in range(6):\n",
        "                            for f in range(self.world_size):\n",
        "                                qcs[e].compose(\n",
        "                                    feature_map[f], \n",
        "                                    qubits=range(self.n_qubits*f,self.n_qubits*(f+1),1), \n",
        "                                    inplace=True\n",
        "                                )\n",
        "                            \n",
        "                        original_ansatz = FraxisAnsatz(self.n_qubits, self.params[d])\n",
        "                        for e in range(6):\n",
        "                            for f in range(self.world_size):\n",
        "                                qcs[e].compose(\n",
        "                                    original_ansatz, \n",
        "                                    qubits=range(self.n_qubits*f,self.n_qubits*(f+1),1), \n",
        "                                    inplace=True\n",
        "                                )\n",
        "\n",
        "                    for d in range(6):\n",
        "                        for f in range(self.world_size):\n",
        "                            qcs[d].compose(\n",
        "                                feature_map[f], \n",
        "                                qubits=range(self.n_qubits*f,self.n_qubits*(f+1),1), \n",
        "                                inplace=True\n",
        "                            )\n",
        "                        \n",
        "                    ansatzs = replace_FraxisAnsatz(self.n_qubits, b, self.params[a])\n",
        "                    for d in range(6):\n",
        "                        for f in range(self.world_size):\n",
        "                            qcs[d].compose(\n",
        "                                ansatzs[d], \n",
        "                                qubits=range(self.n_qubits*f,self.n_qubits*(f+1),1), \n",
        "                                inplace=True\n",
        "                            )\n",
        "                                        \n",
        "                    for d in range(a+1,self.layer_size,1):\n",
        "                        for e in range(6):\n",
        "                            for f in range(self.world_size):\n",
        "                                qcs[e].compose(\n",
        "                                    feature_map[f], \n",
        "                                    qubits=range(self.n_qubits*f,self.n_qubits*(f+1),1), \n",
        "                                    inplace=True\n",
        "                                )\n",
        "                            \n",
        "                        original_ansatz = FraxisAnsatz(self.n_qubits, self.params[d])\n",
        "                        for e in range(6):\n",
        "                            for f in range(self.world_size):\n",
        "                                qcs[e].compose(\n",
        "                                    original_ansatz, \n",
        "                                    qubits=range(self.n_qubits*f,self.n_qubits*(f+1),1), \n",
        "                                    inplace=True\n",
        "                                )\n",
        "\n",
        "                    for d in range(6):\n",
        "                        cr = ClassicalRegister(self.world_size)\n",
        "                        qcs[d].add_register(cr)\n",
        "                        qcs[d].measure(\n",
        "                            range(0,self.world_size*self.n_qubits,self.n_qubits),\n",
        "                            cr\n",
        "                        )\n",
        "                    result = sampler.run(\n",
        "                        circuits=qcs,\n",
        "                    ).result().quasi_dists\n",
        "\n",
        "                    r6s = np.zeros((6,self.world_size))\n",
        "                    for d in range(6):\n",
        "                        #print(result[d])\n",
        "                        for bits in result[d]:\n",
        "                            for e in range(self.world_size):\n",
        "                                if (bits>>(e))%2 == 1:\n",
        "                                    r6s[d, e] -= result[d][bits]\n",
        "                                else:\n",
        "                                    r6s[d, e] += result[d][bits]\n",
        "                                    \n",
        "                    R[0,0] += np.sum(y[c*self.world_size:(c+1)*self.world_size] * 2 * r6s[0])\n",
        "                    R[0,1] += np.sum(y[c*self.world_size:(c+1)*self.world_size] * (2 * r6s[3] - r6s[0] - r6s[1]))\n",
        "                    R[0,2] += np.sum(y[c*self.world_size:(c+1)*self.world_size] * (2 * r6s[4] - r6s[0] - r6s[2]))\n",
        "                    R[1,1] += np.sum(y[c*self.world_size:(c+1)*self.world_size] * 2 * r6s[1])\n",
        "                    R[1,2] += np.sum(y[c*self.world_size:(c+1)*self.world_size] * (2 * r6s[5] - r6s[1] - r6s[2]))\n",
        "                    R[2,2] += np.sum(y[c*self.world_size:(c+1)*self.world_size] * 2 * r6s[2])\n",
        "                R[1,0] = R[0,1]\n",
        "                R[2,0] = R[0,2]\n",
        "                R[2,1] = R[1,2]\n",
        "\n",
        "                eigenvalues, eigenvectors = np.linalg.eigh(R)\n",
        "                \n",
        "                self.params[a,b,:] = eigenvectors[0:2,np.argmax(eigenvalues)]\n",
        "                \n",
        "                print(np.max(eigenvalues))\n",
        "\n",
        "                acc1, sc1 = self.eval(X,y,sampler)\n",
        "                if abs(np.max(eigenvalues)-sc1)>1e-4:\n",
        "                    self.params[a,b,:] *= -1\n",
        "                    acc1, sc1 = self.eval(X,y,sampler) \n",
        "                print('ACC_train: ',acc1,'\\nSCORE_train: ',sc1)\n",
        "                \n",
        "                acc1, sc1 = self.eval(X2,y2,sampler)\n",
        "                print('ACC_test: ',acc1,'\\nSCORE_test: ',sc1)\n",
        "        print(self.params)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M=100\n",
        "N=317"
      ],
      "metadata": {
        "id": "AZ-6ywBWHjBz"
      },
      "id": "AZ-6ywBWHjBz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f088bb7b-3f6e-4e51-94f3-76c28111ebc0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f088bb7b-3f6e-4e51-94f3-76c28111ebc0",
        "outputId": "bb4612ae-0576-4aae-870a-099d8886af8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89.29345015190003\n",
            "ACC_train:  84 \n",
            "SCORE_train:  89.29345015189998\n",
            "ACC_test:  212 \n",
            "SCORE_test:  154.26748997001033\n",
            "89.92624462902329\n",
            "ACC_train:  84 \n",
            "SCORE_train:  89.92624462902323\n",
            "ACC_test:  214 \n",
            "SCORE_test:  158.0158369750918\n",
            "90.27106777001008\n",
            "ACC_train:  85 \n",
            "SCORE_train:  90.2710677700101\n",
            "ACC_test:  213 \n",
            "SCORE_test:  160.20567219642885\n",
            "90.34636588504412\n",
            "ACC_train:  84 \n",
            "SCORE_train:  90.34636588504416\n",
            "ACC_test:  215 \n",
            "SCORE_test:  163.5566996430252\n",
            "93.05189716865415\n",
            "ACC_train:  85 \n",
            "SCORE_train:  93.05189716865412\n",
            "ACC_test:  222 \n",
            "SCORE_test:  161.48728629561367\n",
            "93.05189716865412\n",
            "ACC_train:  85 \n",
            "SCORE_train:  93.05189716865412\n",
            "ACC_test:  222 \n",
            "SCORE_test:  161.48728629561367\n",
            "[[[ 0.50016189  0.86206044]\n",
            "  [ 0.09883038 -0.00196996]]\n",
            "\n",
            " [[-0.00838341  0.04801708]\n",
            "  [-0.00483605 -0.04257315]]\n",
            "\n",
            " [[ 0.09497449  0.07428056]\n",
            "  [ 1.          0.        ]]]\n",
            "_______________NEW________________ 0\n",
            "94.14677739437771\n",
            "ACC_train:  86 \n",
            "SCORE_train:  94.14677739437761\n",
            "ACC_test:  225 \n",
            "SCORE_test:  175.77432308572995\n",
            "94.18043811840022\n",
            "ACC_train:  86 \n",
            "SCORE_train:  94.18043811840016\n",
            "ACC_test:  225 \n",
            "SCORE_test:  174.30641866053858\n",
            "95.40951761769645\n",
            "ACC_train:  85 \n",
            "SCORE_train:  95.40951761769647\n",
            "ACC_test:  223 \n",
            "SCORE_test:  176.56631222152942\n",
            "95.58782803201458\n",
            "ACC_train:  85 \n",
            "SCORE_train:  95.58782803201457\n",
            "ACC_test:  223 \n",
            "SCORE_test:  181.03612201967607\n",
            "96.56465910779849\n",
            "ACC_train:  86 \n",
            "SCORE_train:  96.56465910779852\n",
            "ACC_test:  222 \n",
            "SCORE_test:  182.04226230977397\n",
            "96.56465910779852\n",
            "ACC_train:  86 \n",
            "SCORE_train:  96.56465910779852\n",
            "ACC_test:  222 \n",
            "SCORE_test:  182.04226230977397\n",
            "[[[-0.46882399 -0.88328837]\n",
            "  [ 0.11255273  0.01589326]]\n",
            "\n",
            " [[-0.0600095   0.1154639 ]\n",
            "  [ 0.03024974 -0.06203977]]\n",
            "\n",
            " [[ 0.14880578  0.11948845]\n",
            "  [ 1.          0.        ]]]\n",
            "_______________NEW________________ 1\n",
            "97.14036223075794\n",
            "ACC_train:  86 \n",
            "SCORE_train:  97.14036223075786\n",
            "ACC_test:  222 \n",
            "SCORE_test:  182.0294094578244\n",
            "97.33573976305873\n",
            "ACC_train:  86 \n",
            "SCORE_train:  97.33573976305875\n",
            "ACC_test:  221 \n",
            "SCORE_test:  178.14887056701016\n",
            "98.25766515470701\n",
            "ACC_train:  86 \n",
            "SCORE_train:  98.25766515470698\n",
            "ACC_test:  224 \n",
            "SCORE_test:  183.114694309085\n",
            "98.42163750114153\n",
            "ACC_train:  86 \n",
            "SCORE_train:  98.4216375011415\n",
            "ACC_test:  226 \n",
            "SCORE_test:  187.49368582689564\n",
            "98.86355487512697\n",
            "ACC_train:  85 \n",
            "SCORE_train:  98.86355487512697\n",
            "ACC_test:  229 \n",
            "SCORE_test:  194.88766914971464\n",
            "98.863554875127\n",
            "ACC_train:  85 \n",
            "SCORE_train:  98.86355487512697\n",
            "ACC_test:  229 \n",
            "SCORE_test:  194.88766914971464\n",
            "[[[-0.40343819 -0.9138031 ]\n",
            "  [ 0.13137778  0.05945364]]\n",
            "\n",
            " [[-0.09318746  0.18182406]\n",
            "  [ 0.06223289 -0.07912853]]\n",
            "\n",
            " [[ 0.16961751  0.16107164]\n",
            "  [ 1.          0.        ]]]\n",
            "_______________NEW________________ 2\n",
            "99.48988051850633\n",
            "ACC_train:  85 \n",
            "SCORE_train:  99.48988051850624\n",
            "ACC_test:  225 \n",
            "SCORE_test:  190.7603278621337\n",
            "99.72352883199923\n",
            "ACC_train:  84 \n",
            "SCORE_train:  99.72352883199919\n",
            "ACC_test:  224 \n",
            "SCORE_test:  187.5948109020762\n",
            "100.48494593750974\n",
            "ACC_train:  85 \n",
            "SCORE_train:  100.48494593750969\n",
            "ACC_test:  230 \n",
            "SCORE_test:  193.5830602752135\n",
            "100.52752395780107\n",
            "ACC_train:  85 \n",
            "SCORE_train:  100.52752395780112\n",
            "ACC_test:  231 \n",
            "SCORE_test:  195.60986970298603\n",
            "100.96851721567717\n",
            "ACC_train:  86 \n",
            "SCORE_train:  100.96851721567717\n",
            "ACC_test:  238 \n",
            "SCORE_test:  208.8596598083543\n",
            "100.96851721567715\n",
            "ACC_train:  86 \n",
            "SCORE_train:  100.96851721567717\n",
            "ACC_test:  238 \n",
            "SCORE_test:  208.8596598083543\n",
            "[[[-0.32769396 -0.94079049]\n",
            "  [ 0.16451764  0.09991126]]\n",
            "\n",
            " [[-0.11606236  0.24517703]\n",
            "  [ 0.07135236 -0.09581481]]\n",
            "\n",
            " [[ 0.17099366  0.20753873]\n",
            "  [ 1.          0.        ]]]\n",
            "_______________NEW________________ 3\n",
            "101.5646590527532\n",
            "ACC_train:  85 \n",
            "SCORE_train:  101.56465905275307\n",
            "ACC_test:  235 \n",
            "SCORE_test:  205.2396145443663\n",
            "101.7643694227813\n",
            "ACC_train:  85 \n",
            "SCORE_train:  101.76436942278129\n",
            "ACC_test:  237 \n",
            "SCORE_test:  202.9922325141829\n",
            "102.35504238926143\n",
            "ACC_train:  85 \n",
            "SCORE_train:  102.35504238926143\n",
            "ACC_test:  237 \n",
            "SCORE_test:  208.06266703444413\n",
            "102.3695413333275\n",
            "ACC_train:  86 \n",
            "SCORE_train:  102.3695413333275\n",
            "ACC_test:  238 \n",
            "SCORE_test:  207.53891446485036\n",
            "102.84006606181876\n",
            "ACC_train:  86 \n",
            "SCORE_train:  102.84006606181872\n",
            "ACC_test:  255 \n",
            "SCORE_test:  222.7228434237438\n",
            "102.84006606181877\n",
            "ACC_train:  86 \n",
            "SCORE_train:  102.84006606181872\n",
            "ACC_test:  255 \n",
            "SCORE_test:  222.72284342374385\n",
            "[[[-0.26211775 -0.95596426]\n",
            "  [ 0.20096744  0.13098212]]\n",
            "\n",
            " [[-0.13514322  0.30023065]\n",
            "  [ 0.06213872 -0.10409237]]\n",
            "\n",
            " [[ 0.1638938   0.25472809]\n",
            "  [ 0.          0.81373347]]]\n",
            "_______________NEW________________ 4\n",
            "103.35670882010196\n",
            "ACC_train:  86 \n",
            "SCORE_train:  103.35670882010186\n",
            "ACC_test:  251 \n",
            "SCORE_test:  220.94417410640403\n",
            "103.49243901785945\n",
            "ACC_train:  85 \n",
            "SCORE_train:  103.49243901785945\n",
            "ACC_test:  252 \n",
            "SCORE_test:  219.34412999200555\n",
            "103.86859977783286\n",
            "ACC_train:  86 \n",
            "SCORE_train:  103.86859977783278\n",
            "ACC_test:  256 \n",
            "SCORE_test:  222.81097408557966\n",
            "103.91353687633706\n",
            "ACC_train:  86 \n",
            "SCORE_train:  103.91353687633698\n",
            "ACC_test:  253 \n",
            "SCORE_test:  220.89465394774604\n",
            "104.31084275790425\n",
            "ACC_train:  89 \n",
            "SCORE_train:  104.31084275790423\n",
            "ACC_test:  267 \n",
            "SCORE_test:  234.63549342011075\n",
            "104.31084275790427\n",
            "ACC_train:  89 \n",
            "SCORE_train:  104.31084275790421\n",
            "ACC_test:  267 \n",
            "SCORE_test:  234.6354934201108\n",
            "[[[-0.21442444 -0.95951632]\n",
            "  [ 0.23450056  0.15136703]]\n",
            "\n",
            " [[-0.15086534  0.34292417]\n",
            "  [ 0.04472377 -0.10372015]]\n",
            "\n",
            " [[ 0.15552996  0.297134  ]\n",
            "  [-0.          0.78051271]]]\n",
            "_______________NEW________________ 5\n",
            "104.70650537272473\n",
            "ACC_train:  89 \n",
            "SCORE_train:  104.7065053727247\n",
            "ACC_test:  267 \n",
            "SCORE_test:  234.41091543169418\n",
            "104.78259021089698\n",
            "ACC_train:  90 \n",
            "SCORE_train:  104.78259021089703\n",
            "ACC_test:  268 \n",
            "SCORE_test:  233.36820605239583\n",
            "104.98246073155815\n",
            "ACC_train:  90 \n",
            "SCORE_train:  104.98246073155816\n",
            "ACC_test:  269 \n",
            "SCORE_test:  235.43122684615656\n",
            "105.0389560901228\n",
            "ACC_train:  90 \n",
            "SCORE_train:  105.03895609012287\n",
            "ACC_test:  268 \n",
            "SCORE_test:  233.23673973390376\n",
            "105.32005581220096\n",
            "ACC_train:  90 \n",
            "SCORE_train:  105.32005581220103\n",
            "ACC_test:  277 \n",
            "SCORE_test:  244.30410099810982\n",
            "105.32005581220102\n",
            "ACC_train:  90 \n",
            "SCORE_train:  105.320055812201\n",
            "ACC_test:  277 \n",
            "SCORE_test:  244.3041009981098\n",
            "[[[-0.18370553 -0.95518481]\n",
            "  [ 0.26208626  0.16178335]]\n",
            "\n",
            " [[-0.16326574  0.37303371]\n",
            "  [ 0.02710201 -0.09845657]]\n",
            "\n",
            " [[ 0.14877718  0.33221728]\n",
            "  [ 0.         -0.06651901]]]\n",
            "_______________NEW________________ 6\n",
            "105.58054688163773\n",
            "ACC_train:  90 \n",
            "SCORE_train:  105.58054688163766\n",
            "ACC_test:  277 \n",
            "SCORE_test:  244.83537478107328\n",
            "105.6200637983984\n",
            "ACC_train:  90 \n",
            "SCORE_train:  105.62006379839832\n",
            "ACC_test:  275 \n",
            "SCORE_test:  244.2660288512918\n",
            "105.71453414292242\n",
            "ACC_train:  90 \n",
            "SCORE_train:  105.7145341429224\n",
            "ACC_test:  275 \n",
            "SCORE_test:  245.41926248087776\n",
            "105.75950509698541\n",
            "ACC_train:  91 \n",
            "SCORE_train:  105.75950509698546\n",
            "ACC_test:  273 \n",
            "SCORE_test:  243.49781749956716\n",
            "105.93773314478344\n",
            "ACC_train:  90 \n",
            "SCORE_train:  105.93773314478335\n",
            "ACC_test:  276 \n",
            "SCORE_test:  251.94714722602862\n",
            "105.93773314478335\n",
            "ACC_train:  90 \n",
            "SCORE_train:  105.93773314478335\n",
            "ACC_test:  276 \n",
            "SCORE_test:  251.9471472260286\n",
            "[[[-0.16482335 -0.94735412]\n",
            "  [ 0.28299762  0.16516292]]\n",
            "\n",
            " [[-0.17266517  0.39305687]\n",
            "  [ 0.01265134 -0.09161506]]\n",
            "\n",
            " [[ 0.1439073   0.35977977]\n",
            "  [ 1.          0.        ]]]\n",
            "_______________NEW________________ 7\n",
            "106.0899123493457\n",
            "ACC_train:  89 \n",
            "SCORE_train:  106.08991234934571\n",
            "ACC_test:  274 \n",
            "SCORE_test:  252.6769755851363\n",
            "106.11106353548439\n",
            "ACC_train:  91 \n",
            "SCORE_train:  106.11106353548436\n",
            "ACC_test:  273 \n",
            "SCORE_test:  252.42992374830342\n",
            "106.15307979430773\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.15307979430767\n",
            "ACC_test:  274 \n",
            "SCORE_test:  253.0703658216636\n",
            "106.18237856943136\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.1823785694314\n",
            "ACC_test:  275 \n",
            "SCORE_test:  251.55840814231826\n",
            "106.28729176309619\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.28729176309606\n",
            "ACC_test:  277 \n",
            "SCORE_test:  257.8222112824106\n",
            "106.28729176309608\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.28729176309606\n",
            "ACC_test:  277 \n",
            "SCORE_test:  257.82221128241065\n",
            "[[[-0.15317426 -0.93902902]\n",
            "  [ 0.29815075  0.16475403]]\n",
            "\n",
            " [[-0.17953862  0.40600751]\n",
            "  [ 0.00175912 -0.08501381]]\n",
            "\n",
            " [[ 0.14052074  0.38069445]\n",
            "  [ 0.          0.32217263]]]\n",
            "_______________NEW________________ 8\n",
            "106.37047396520279\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.37047396520273\n",
            "ACC_test:  273 \n",
            "SCORE_test:  258.50452109377557\n",
            "106.38227867020316\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.38227867020312\n",
            "ACC_test:  274 \n",
            "SCORE_test:  258.42702285490014\n",
            "106.40056793452257\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.40056793452253\n",
            "ACC_test:  275 \n",
            "SCORE_test:  258.78822929260525\n",
            "106.41784502722808\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.41784502722808\n",
            "ACC_test:  275 \n",
            "SCORE_test:  257.6537565263528\n",
            "106.4764981360164\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.4764981360164\n",
            "ACC_test:  275 \n",
            "SCORE_test:  262.2111546106649\n",
            "106.47649813601637\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.47649813601637\n",
            "ACC_test:  275 \n",
            "SCORE_test:  262.2111546106649\n",
            "[[[-0.14579486 -0.93162955]\n",
            "  [ 0.30894993  0.16283866]]\n",
            "\n",
            " [[-0.18445344  0.41431927]\n",
            "  [-0.00616936 -0.07940388]]\n",
            "\n",
            " [[ 0.13821323  0.3961962 ]\n",
            "  [ 1.          0.        ]]]\n",
            "_______________NEW________________ 9\n",
            "106.52054192577158\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.52054192577147\n",
            "ACC_test:  275 \n",
            "SCORE_test:  262.76858184401664\n",
            "106.52718318599717\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.52718318599715\n",
            "ACC_test:  275 \n",
            "SCORE_test:  262.7623003737031\n",
            "106.53519243764762\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.5351924376476\n",
            "ACC_test:  276 \n",
            "SCORE_test:  262.9697424151795\n",
            "106.54478516295302\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.54478516295298\n",
            "ACC_test:  276 \n",
            "SCORE_test:  262.1395663461866\n",
            "106.57648415879592\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.5764841587959\n",
            "ACC_test:  277 \n",
            "SCORE_test:  265.418135644087\n",
            "106.5764841587959\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.5764841587959\n",
            "ACC_test:  277 \n",
            "SCORE_test:  265.418135644087\n",
            "[[[-0.14095953 -0.92559262]\n",
            "  [ 0.31662698  0.16062071]]\n",
            "\n",
            " [[-0.18794249  0.41968142]\n",
            "  [-0.01184333 -0.07495661]]\n",
            "\n",
            " [[ 0.13666435  0.40751556]\n",
            "  [ 1.          0.        ]]]\n",
            "_______________NEW________________ 10\n",
            "106.5994418118474\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.59944181184737\n",
            "ACC_test:  276 \n",
            "SCORE_test:  265.8451920248055\n",
            "106.60313360634164\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.60313360634161\n",
            "ACC_test:  276 \n",
            "SCORE_test:  265.86242082356506\n",
            "106.60672471029801\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.606724710298\n",
            "ACC_test:  276 \n",
            "SCORE_test:  265.9838284060815\n",
            "106.61184333120246\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.6118433312025\n",
            "ACC_test:  277 \n",
            "SCORE_test:  265.38547272740664\n",
            "106.62862039886613\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.62862039886612\n",
            "ACC_test:  277 \n",
            "SCORE_test:  267.7301428178549\n",
            "106.62862039886613\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.62862039886612\n",
            "ACC_test:  277 \n",
            "SCORE_test:  267.7301428178549\n",
            "[[[-0.1376928  -0.92089585]\n",
            "  [ 0.32209696  0.15860511]]\n",
            "\n",
            " [[-0.19042448  0.42318809]\n",
            "  [-0.01586577 -0.07157613]]\n",
            "\n",
            " [[ 0.13563385  0.4157081 ]\n",
            "  [ 0.         -0.01798298]]]\n",
            "_______________NEW________________ 11\n",
            "106.6404904680227\n",
            "ACC_train:  91 \n",
            "SCORE_train:  106.64049046802272\n",
            "ACC_test:  276 \n",
            "SCORE_test:  268.04658101129627\n",
            "106.64251052170108\n",
            "ACC_train:  91 \n",
            "SCORE_train:  106.64251052170096\n",
            "ACC_test:  276 \n",
            "SCORE_test:  268.0680806832302\n",
            "106.64417201524353\n",
            "ACC_train:  91 \n",
            "SCORE_train:  106.64417201524356\n",
            "ACC_test:  276 \n",
            "SCORE_test:  268.1406876940715\n",
            "106.6468340244812\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.64683402448118\n",
            "ACC_test:  277 \n",
            "SCORE_test:  267.71339235980815\n",
            "106.6556058754102\n",
            "ACC_train:  91 \n",
            "SCORE_train:  106.65560587541015\n",
            "ACC_test:  276 \n",
            "SCORE_test:  269.3861435680572\n",
            "106.65560587541016\n",
            "ACC_train:  91 \n",
            "SCORE_train:  106.65560587541016\n",
            "ACC_test:  276 \n",
            "SCORE_test:  269.38614356805726\n",
            "[[[-0.13543522 -0.91734462]\n",
            "  [ 0.32600609  0.15694586]]\n",
            "\n",
            " [[-0.19220001  0.42552276]\n",
            "  [-0.0187034  -0.06907277]]\n",
            "\n",
            " [[ 0.13495012  0.42160892]\n",
            "  [ 1.          0.        ]]]\n",
            "_______________NEW________________ 12\n",
            "106.66171963097776\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.66171963097766\n",
            "ACC_test:  276 \n",
            "SCORE_test:  269.61659773478107\n",
            "106.66281006615321\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.66281006615313\n",
            "ACC_test:  276 \n",
            "SCORE_test:  269.6358625751422\n",
            "106.66360330831222\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.66360330831219\n",
            "ACC_test:  276 \n",
            "SCORE_test:  269.68035989818947\n",
            "106.6649667431789\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.66496674317891\n",
            "ACC_test:  277 \n",
            "SCORE_test:  269.3767574781246\n",
            "106.66952300206994\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.66952300206992\n",
            "ACC_test:  277 \n",
            "SCORE_test:  270.56975092118915\n",
            "106.6695230020699\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.66952300206992\n",
            "ACC_test:  277 \n",
            "SCORE_test:  270.56975092118915\n",
            "[[[-0.13385152 -0.91470682]\n",
            "  [ 0.32880677  0.15564685]]\n",
            "\n",
            " [[-0.19347745  0.42710609]\n",
            "  [-0.02070174 -0.06724843]]\n",
            "\n",
            " [[ 0.13449548  0.42584918]\n",
            "  [ 0.         -0.09040321]]]\n",
            "_______________NEW________________ 13\n",
            "106.6726680253519\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.67266802535187\n",
            "ACC_test:  276 \n",
            "SCORE_test:  270.7361628513881\n",
            "106.67325064558715\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.67325064558716\n",
            "ACC_test:  275 \n",
            "SCORE_test:  270.75166096258005\n",
            "106.67363966205286\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.67363966205288\n",
            "ACC_test:  276 \n",
            "SCORE_test:  270.7796457111328\n",
            "106.67433258162146\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.67433258162146\n",
            "ACC_test:  277 \n",
            "SCORE_test:  270.5643658013158\n",
            "106.67669186842795\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.67669186842801\n",
            "ACC_test:  277 \n",
            "SCORE_test:  271.4158838658682\n",
            "106.67669186842801\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.676691868428\n",
            "ACC_test:  277 \n",
            "SCORE_test:  271.4158838658681\n",
            "[[[-0.13273007 -0.91276924]\n",
            "  [ 0.33081704  0.15465843]]\n",
            "\n",
            " [[-0.19440055  0.42819774]\n",
            "  [-0.02210966 -0.06593134]]\n",
            "\n",
            " [[ 0.13419151  0.42889368]\n",
            "  [ 0.         -0.37392163]]]\n",
            "_______________NEW________________ 14\n",
            "106.67831023945632\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.67831023945627\n",
            "ACC_test:  276 \n",
            "SCORE_test:  271.53560047605447\n",
            "106.67861924652331\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.67861924652331\n",
            "ACC_test:  276 \n",
            "SCORE_test:  271.5475050429893\n",
            "106.6788140144834\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.6788140144834\n",
            "ACC_test:  276 \n",
            "SCORE_test:  271.56555593297526\n",
            "106.67916522048807\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.67916522048812\n",
            "ACC_test:  276 \n",
            "SCORE_test:  271.4129022924204\n",
            "106.68038563477495\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.6803856347749\n",
            "ACC_test:  276 \n",
            "SCORE_test:  272.02149993252806\n",
            "106.6803856347749\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68038563477486\n",
            "ACC_test:  276 \n",
            "SCORE_test:  272.02149993252795\n",
            "[[[-0.13193131 -0.91135593]\n",
            "  [ 0.33226193  0.15391921]]\n",
            "\n",
            " [[-0.19506945  0.42896053]\n",
            "  [-0.02310343 -0.06498527]]\n",
            "\n",
            " [[ 0.13398674  0.43107972]\n",
            "  [ 1.          0.        ]]]\n",
            "_______________NEW________________ 15\n",
            "106.68121938982547\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68121938982547\n",
            "ACC_test:  276 \n",
            "SCORE_test:  272.1075153022615\n",
            "106.68138242963914\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68138242963909\n",
            "ACC_test:  276 \n",
            "SCORE_test:  272.1164572754261\n",
            "106.68148140226711\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68148140226704\n",
            "ACC_test:  276 \n",
            "SCORE_test:  272.128372534231\n",
            "106.68165949952362\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68165949952366\n",
            "ACC_test:  277 \n",
            "SCORE_test:  272.01999107404134\n",
            "106.6822908769384\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68229087693841\n",
            "ACC_test:  277 \n",
            "SCORE_test:  272.4556253210944\n",
            "106.68229087693841\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68229087693841\n",
            "ACC_test:  277 \n",
            "SCORE_test:  272.4556253210944\n",
            "[[[-0.13136027 -0.91032949]\n",
            "  [ 0.33330147  0.15337242]]\n",
            "\n",
            " [[-0.1955548   0.42949897]\n",
            "  [-0.02380668 -0.06430727]]\n",
            "\n",
            " [[ 0.1338476   0.4326501 ]\n",
            "  [ 1.          0.        ]]]\n",
            "_______________NEW________________ 16\n",
            "106.68272107424488\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68272107424491\n",
            "ACC_test:  276 \n",
            "SCORE_test:  272.51742440521264\n",
            "106.68280678609177\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68280678609182\n",
            "ACC_test:  276 \n",
            "SCORE_test:  272.52406161564244\n",
            "106.68285759032561\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.6828575903257\n",
            "ACC_test:  276 \n",
            "SCORE_test:  272.53208481851203\n",
            "106.68294811163355\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68294811163358\n",
            "ACC_test:  276 \n",
            "SCORE_test:  272.45498958878375\n",
            "106.68327498350313\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68327498350315\n",
            "ACC_test:  277 \n",
            "SCORE_test:  272.7672775916371\n",
            "106.68327498350314\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68327498350315\n",
            "ACC_test:  277 \n",
            "SCORE_test:  272.7672775916371\n",
            "[[[-0.13095102 -0.90958599]\n",
            "  [ 0.33404996  0.15297089]]\n",
            "\n",
            " [[-0.19590713  0.42988185]\n",
            "  [-0.02430577 -0.0638217 ]]\n",
            "\n",
            " [[ 0.13375224  0.43377896]\n",
            "  [ 1.          0.        ]]]\n",
            "_______________NEW________________ 17\n",
            "106.68349731501709\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68349731501702\n",
            "ACC_test:  276 \n",
            "SCORE_test:  272.81170047532737\n",
            "106.68354226070275\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68354226070275\n",
            "ACC_test:  276 \n",
            "SCORE_test:  272.81659253193834\n",
            "106.68356851182646\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68356851182638\n",
            "ACC_test:  276 \n",
            "SCORE_test:  272.82208425993275\n",
            "106.68361466585411\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68361466585412\n",
            "ACC_test:  276 \n",
            "SCORE_test:  272.767126750139\n",
            "106.68378405065681\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68378405065675\n",
            "ACC_test:  277 \n",
            "SCORE_test:  272.99129343056165\n",
            "106.6837840506568\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68378405065675\n",
            "ACC_test:  277 \n",
            "SCORE_test:  272.99129343056165\n",
            "[[[-0.13065721 -0.9090483 ]\n",
            "  [ 0.33458919  0.15267748]]\n",
            "\n",
            " [[-0.19616285  0.43015551]\n",
            "  [-0.02466095 -0.06347383]]\n",
            "\n",
            " [[ 0.13368632  0.43459102]\n",
            "  [ 0.         -0.92584764]]]\n",
            "_______________NEW________________ 18\n",
            "106.68389913105987\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68389913105985\n",
            "ACC_test:  276 \n",
            "SCORE_test:  273.02324771341387\n",
            "106.68392265816726\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68392265816723\n",
            "ACC_test:  276 \n",
            "SCORE_test:  273.02683689881536\n",
            "106.68393627882138\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68393627882128\n",
            "ACC_test:  276 \n",
            "SCORE_test:  273.03064526230384\n",
            "106.6839598908829\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68395989088299\n",
            "ACC_test:  276 \n",
            "SCORE_test:  272.99138589145286\n",
            "106.68404775190919\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68404775190909\n",
            "ACC_test:  276 \n",
            "SCORE_test:  273.1524843927563\n",
            "106.6840477519091\n",
            "ACC_train:  90 \n",
            "SCORE_train:  106.68404775190908\n",
            "ACC_test:  276 \n",
            "SCORE_test:  273.1524843927563\n",
            "[[[-0.130446   -0.90865981]\n",
            "  [ 0.33497785  0.1524638 ]]\n",
            "\n",
            " [[-0.19634835  0.43035179]\n",
            "  [-0.02491438 -0.06322442]]\n",
            "\n",
            " [[ 0.13364041  0.43517556]\n",
            "  [ 1.          0.        ]]]\n",
            "_______________NEW________________ 19\n"
          ]
        }
      ],
      "source": [
        "model = FraxClassify_sim(2, 3, 1, None)\n",
        "for i in range(20):\n",
        "    model.fit_and_eval(X1[0:M], y1[0:M], X2[0:N], y2[0:N])\n",
        "    print('_______________NEW________________',i)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g5W_xCDxIcQS"
      },
      "id": "g5W_xCDxIcQS",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}