{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from math import sqrt\n",
        "import numpy as np\n",
        "import torch.multiprocessing as mp\n",
        "import os\n",
        "import torch.distributed as dist\n",
        "import time"
      ],
      "metadata": {
        "id": "qMvHb1FYuMYY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "u0La-30aqq43"
      },
      "outputs": [],
      "source": [
        "def kronecker(A, B):\n",
        "    if not isinstance(A, torch.Tensor):\n",
        "        return B\n",
        "    return torch.einsum(\"ab,cd->acbd\", A, B).view(A.size(0)*B.size(0),  A.size(1)*B.size(1))\n",
        "\n",
        "Z = torch.tensor([\n",
        "    [1.0, 0],\n",
        "    [0, -1.0]\n",
        "], dtype=torch.cfloat)\n",
        "\n",
        "X = torch.tensor([\n",
        "    [0, 1.0],\n",
        "    [1.0,  0]\n",
        "], dtype=torch.cfloat)\n",
        "\n",
        "Y = torch.tensor([\n",
        "    [0, -1.0j],\n",
        "    [1.0j, 0]\n",
        "], dtype=torch.cfloat)\n",
        "\n",
        "H = math.sqrt(2)/2*torch.tensor([\n",
        "    [1, 1],\n",
        "    [1, -1]\n",
        "], dtype=torch.cfloat)\n",
        "\n",
        "I = torch.eye(2, dtype=torch.cfloat)\n",
        "\n",
        "def RX(phi):\n",
        "    gate = torch.zeros((2, 2), dtype=torch.cfloat)\n",
        "    gate[0, 0], gate[0, 1], gate[1, 0], gate[1, 1] = torch.cos(phi/2), torch.complex(torch.tensor(0, dtype=torch.float32), -torch.sin(phi/2)), torch.complex(torch.tensor(0, dtype=torch.float32), -torch.sin(phi/2)), torch.cos(phi/2)\n",
        "    return gate.to(phi.device)\n",
        "\n",
        "def RY(phi):\n",
        "    gate = torch.zeros((2, 2), dtype=torch.cfloat)\n",
        "    gate[0, 0], gate[0, 1], gate[1, 0], gate[1, 1] = torch.cos(phi/2), -torch.sin(phi/2), torch.sin(phi/2), torch.cos(phi/2)\n",
        "    return gate.to(phi.device)\n",
        "\n",
        "def RZ(phi):\n",
        "    gate = torch.zeros((2, 2), dtype=torch.cfloat)\n",
        "    gate[0, 0], gate[1, 1] = torch.complex(torch.cos(phi/2), -torch.sin(phi/2)), torch.complex(torch.cos(phi/2), torch.sin(phi/2))\n",
        "    return gate.to(phi.device)\n",
        "\n",
        "def Rot(alpha, beta, theta):\n",
        "    return torch.mm(torch.mm(RZ(alpha), RY(beta)), RZ(theta))\n",
        "\n",
        "def Frax(n):\n",
        "    axis = n / torch.norm(n)\n",
        "    gate = torch.zeros((2, 2), dtype=torch.cfloat)\n",
        "    gate[0, 0], gate[0, 1], gate[1, 0], gate[1, 1] = -axis[2]*1j, -axis[0]*1j-axis[1], -axis[0]*1j+axis[1], axis[2]*1j\n",
        "    return gate.to(n.device)\n",
        "\n",
        "def State00():\n",
        "    state = torch.zeros((2, 2), dtype=torch.cfloat)\n",
        "    state[0, 0] = 1\n",
        "    return state\n",
        "\n",
        "def State11():\n",
        "    state = torch.zeros((2, 2), dtype=torch.cfloat)\n",
        "    state[1, 1] = 1\n",
        "    return state\n",
        "\n",
        "def CNOT(wires=[0, 1]):\n",
        "    # First qubit : Cnntrol, Second qubit : Flipped\n",
        "    if wires[0] < wires[1]:\n",
        "        return torch.tensor([\n",
        "            [1,0,0,0],\n",
        "            [0,1,0,0],\n",
        "            [0,0,0,1],\n",
        "            [0,0,1,0]], dtype=torch.cfloat)\n",
        "    else:\n",
        "        return torch.tensor([\n",
        "            [1,0,0,0],\n",
        "            [0,0,0,1],\n",
        "            [0,0,1,0],\n",
        "            [0,1,0,0]], dtype=torch.cfloat)\n",
        "    \n",
        "RGate = {\n",
        "    'RX': RX,\n",
        "    'RY': RY,\n",
        "    'RZ': RZ\n",
        "}\n",
        "\n",
        "CZ = torch.tensor([\n",
        "    [1,0,0,0],\n",
        "    [0,1,0,0], \n",
        "    [0,0,1,0], \n",
        "    [0,0,0,-1]], dtype=torch.cfloat)\n",
        "\n",
        "def CRR(phi, wires=[0, 1], name='RX'):\n",
        "    if wires[0] < wires[1]:\n",
        "        first, second = State00(), State11()\n",
        "        for i in range(wires[0], wires[1]):\n",
        "            if i == wires[1] - 1:\n",
        "                first = kronecker(first, torch.eye(2))\n",
        "                second = kronecker(second, RGate[name](phi))\n",
        "            else:\n",
        "                first = kronecker(first, torch.eye(2))\n",
        "                second = kronecker(second, torch.eye(2))\n",
        "        return first + second\n",
        "    else:\n",
        "        first, second = torch.eye(2), RGate[name](phi)\n",
        "        for i in range(wires[1], wires[0]):\n",
        "            if i == wires[0] - 1:\n",
        "                first = kronecker(first, State00)\n",
        "                second = kronecker(second, State11)\n",
        "            else:\n",
        "                first = kronecker(first, torch.eye(2))\n",
        "                second = kronecker(second, torch.eye(2))\n",
        "        return first + second"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def CZ_layer(n_qubits):\n",
        "    if n_qubits == 2:\n",
        "        return CZ\n",
        "    gate1 = CZ\n",
        "    for i in range(2, n_qubits, 2):\n",
        "        if i+1 < n_qubits:\n",
        "            gate1 = kronecker(gate1, CZ)\n",
        "        else:\n",
        "            gate1 = kronecker(gate1, I)\n",
        "    gate2 = CZ\n",
        "    gate2 = kronecker(I, gate2)\n",
        "    for i in range(3, n_qubits, 2):\n",
        "        if i+1 < n_qubits:\n",
        "            gate2 = kronecker(gate2, CZ)\n",
        "        else:\n",
        "            gate2 = kronecker(gate2, I)\n",
        "    return torch.mm(gate2, gate1)\n",
        "\n",
        "def Frax_ansatz(n_qubits, param):\n",
        "    # param : torch.Tensor of (n_qubits, 3)\n",
        "    x = 1\n",
        "    for i in range(n_qubits):\n",
        "        x = kronecker(x, Frax(param[i]))\n",
        "    return torch.mm(CZ_layer(n_qubits), x)\n",
        "\n",
        "def replace_Frax_ansatz(n_qubits, measured_qubit, observable, param):\n",
        "    x = 1\n",
        "    for i in range(measured_qubit):\n",
        "        x = kronecker(x, Frax(param[i]))\n",
        "        \n",
        "    if observable == 'X':\n",
        "        x = kronecker(x, X)\n",
        "    elif observable == 'Y':\n",
        "        x = kronecker(x, Y)\n",
        "    elif observable == 'Z':\n",
        "        x = kronecker(x, Z)\n",
        "    elif observable == 'XY':\n",
        "        x = kronecker(x, (X+Y)/sqrt(2))\n",
        "    elif observable == 'XZ':\n",
        "        x = kronecker(x, (X+Z)/sqrt(2))\n",
        "    elif observable == 'YZ':\n",
        "        x = kronecker(x, (Y+Z)/sqrt(2))\n",
        "\n",
        "    for i in range(measured_qubit+1, n_qubits):\n",
        "        x = kronecker(x, Frax(param[i]))\n",
        "    return torch.mm(CZ_layer(n_qubits), x)"
      ],
      "metadata": {
        "id": "6MhKDIATqzOy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def amplitude_embedding(feat, n_qubits):\n",
        "    # feat : torch.tensor of 2^n_qubits elements\n",
        "    if feat.ndim == 1:\n",
        "        feat = feat.reshape(-1,).to(torch.complex64)\n",
        "        feat /= torch.norm(feat)\n",
        "    elif feat.ndim == 2:\n",
        "        feat = feat.reshape(-1, 2**n_qubits,).to(torch.complex64)\n",
        "        feat = feat.transpose(0,1) / torch.norm(feat, dim=1)\n",
        "        feat = feat.transpose(0,1)\n",
        "    return feat"
      ],
      "metadata": {
        "id": "NnzWMxgBqzw3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lastbit_Z(state):\n",
        "    return torch.sum(state[0:len(state):2].abs()**2)-torch.sum(state[1:len(state):2].abs()**2)\n",
        "\n",
        "class FraxClassify():\n",
        "    def __init__(self, n_qubits, layer_size, measure_iter, world_size):\n",
        "        self.n_qubits = n_qubits\n",
        "        self.layer_size = layer_size\n",
        "        self.measure_iter = measure_iter\n",
        "        self.params = (torch.zeros(layer_size, n_qubits, 3) + 1/sqrt(3)).to(torch.complex64)\n",
        "        self.world_size =world_size\n",
        "        self.train_acc = []\n",
        "        self.test_acc = []\n",
        "        \n",
        "    def fit(self, train):\n",
        "        params = self.params\n",
        "        train_feat, train_label = train\n",
        "        x = amplitude_embedding(train_feat, self.n_qubits)\n",
        "        for a in range(self.layer_size):\n",
        "            for b in range(self.n_qubits):\n",
        "                R = torch.zeros(3,3)\n",
        "                for c in range(train_feat.shape[0]):\n",
        "                    y = x[c]\n",
        "                    for d in range(a):\n",
        "                        y = Frax_ansatz(self.n_qubits, params[d]) @ y\n",
        "                    rx = replace_Frax_ansatz(self.n_qubits, b, 'X', params[a]) @ y\n",
        "                    ry = replace_Frax_ansatz(self.n_qubits, b, 'Y', params[a]) @ y\n",
        "                    rz = replace_Frax_ansatz(self.n_qubits, b, 'Z', params[a]) @ y\n",
        "                    rxy = replace_Frax_ansatz(self.n_qubits, b, 'XY', params[a]) @ y\n",
        "                    rxz = replace_Frax_ansatz(self.n_qubits, b, 'XZ', params[a]) @ y\n",
        "                    ryz = replace_Frax_ansatz(self.n_qubits, b, 'YZ', params[a]) @ y\n",
        "                    for d in range(a+1, self.layer_size):\n",
        "                        rx = Frax_ansatz(self.n_qubits, params[d]) @ rx\n",
        "                        ry = Frax_ansatz(self.n_qubits, params[d]) @ ry       \n",
        "                        rz = Frax_ansatz(self.n_qubits, params[d]) @ rz\n",
        "                        rxy = Frax_ansatz(self.n_qubits, params[d]) @ rxy\n",
        "                        rxz = Frax_ansatz(self.n_qubits, params[d]) @ rxz        \n",
        "                        ryz = Frax_ansatz(self.n_qubits, params[d]) @ ryz\n",
        "                        \n",
        "                    rx = lastbit_Z(rx)\n",
        "                    ry = lastbit_Z(ry)\n",
        "                    rz = lastbit_Z(rz)\n",
        "                    rxy = lastbit_Z(rxy)\n",
        "                    rxz = lastbit_Z(rxz)\n",
        "                    ryz = lastbit_Z(ryz)\n",
        "                        \n",
        "                    R[0,0] += train_label[c] * 2 * rx\n",
        "                    R[0,1] += train_label[c] * (2 * rxy-rx-ry)\n",
        "                    R[0,2] += train_label[c] * (2 * rxz-rx-rz)\n",
        "                    R[1,1] += train_label[c] * 2 * ry\n",
        "                    R[1,2] += train_label[c] * (2 * ryz-ry-rz)\n",
        "                    R[2,1] += train_label[c] * 2 * rz\n",
        "                    \n",
        "                R[1,0] = R[0,1]\n",
        "                R[2,0] = R[0,2]\n",
        "                R[2,1] = R[1,2]\n",
        "                group = dist.new_group(range(self.world_size))\n",
        "                dist.all_reduce(R, op=dist.ReduceOp.SUM, group=group)\n",
        "                if (dist.get_rank(group) == 0):\n",
        "                    print(R)\n",
        "                eigenvalues, eigenvectors = torch.linalg.eig(R)\n",
        "                self.params[a, b] = eigenvectors[torch.argmax(eigenvalues.real)]\n",
        "                self.params[a, b] /= torch.norm(self.params[a, b])\n",
        "                \n",
        "    def eval(self, train, test):\n",
        "        test_score = 0\n",
        "        train_score = 0\n",
        "        train_feat, train_label = train\n",
        "        test_feat, test_label = test\n",
        "        train_size = train_label.shape[0]\n",
        "        test_size = test_label.shape[0]\n",
        "        for a in range(test_size):\n",
        "            x = amplitude_embedding(test_feat[a], self.n_qubits)\n",
        "            for b in range(self.layer_size):\n",
        "                x = Frax_ansatz(self.n_qubits, self.params[b]) @ x\n",
        "            test_score += test_label[a] * lastbit_Z(x)\n",
        "        group = dist.new_group(range(self.world_size))\n",
        "        dist.all_reduce(test_score, op=dist.ReduceOp.SUM, group=group)\n",
        "        self.test_acc.append(test_score)\n",
        "        \n",
        "        for a in range(train_size):\n",
        "            x = amplitude_embedding(train_feat[a], self.n_qubits)\n",
        "            for b in range(self.layer_size):\n",
        "                x = Frax_ansatz(self.n_qubits, self.params[b]) @ x\n",
        "            train_score += train_label[a] * lastbit_Z(x)\n",
        "        group = dist.new_group(range(self.world_size))\n",
        "        dist.all_reduce(train_score, op=dist.ReduceOp.SUM, group=group)\n",
        "        self.train_acc.append(train_score)\n",
        "        \n",
        "    def get_accuracy(self):\n",
        "        if dist.get_rank() == 0:\n",
        "            print(self.train_acc, self.test_acc)"
      ],
      "metadata": {
        "id": "Glb5xo-gq82O"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_loader():\n",
        "    try:\n",
        "        test_label = torch.from_numpy(np.load('drive/MyDrive/mnist_test_Label.npy'))\n",
        "        train_label = torch.from_numpy(np.load('drive/MyDrive/mnist_train_Label.npy'))\n",
        "        test_feat = torch.from_numpy(np.load('drive/MyDrive/mnist_test_feat.npy'))\n",
        "        train_feat = torch.from_numpy(np.load('drive/MyDrive/mnist_train_feat.npy'))\n",
        "        return test_label, train_label, test_feat, train_feat\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    \n",
        "def cut_data(train_label, train_feat, test_label, test_feat, rank, world_size):\n",
        "    data_len_min = len(train_feat) // world_size\n",
        "    offset = len(train_feat) % world_size\n",
        "    if rank < offset:\n",
        "        start1 = rank*(data_len_min+1)\n",
        "        end1 = start1+data_len_min+1\n",
        "    else:\n",
        "        start1 = offset*(data_len_min+1)+(rank-offset)*data_len_min\n",
        "        end1 = start1+data_len_min\n",
        "    data_len_min = len(test_feat) // world_size\n",
        "    offset = len(test_feat) % world_size\n",
        "    if rank < offset:\n",
        "        start2 = rank*(data_len_min+1)\n",
        "        end2 = start2+data_len_min+1\n",
        "    else:\n",
        "        start2 = offset*(data_len_min+1)+(rank-offset)*data_len_min\n",
        "        end2 = start2+data_len_min\n",
        "    \n",
        "    return train_label[start1:end1], train_feat[start1:end1], test_label[start2:end2], test_feat[start2:end2]\n",
        "\n",
        "def parallel_train(rank, world_size, layer_size, update_iter, measure_iter):\n",
        "    print('I am ', rank)\n",
        "    n_qubits = 6\n",
        "    test_label, train_label, test_feat, train_feat = data_loader()\n",
        "    train_label, train_feat, test_label, test_feat = cut_data(train_label, train_feat, test_label, test_feat, rank, world_size)\n",
        "    model = FraxClassify(n_qubits, layer_size, measure_iter, world_size)\n",
        "    for i in range(update_iter):\n",
        "        model.fit(train=(train_feat, train_label))\n",
        "        model.eval(train=(train_feat, train_label), test=(test_feat, test_label))\n",
        "    model.get_accuracy()"
      ],
      "metadata": {
        "id": "4l0gLt8JrEsK"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_process(rank, world_size, layer_size, update_iter, measure_iter, fn, backend='gloo'):\n",
        "    os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
        "    os.environ['MASTER_PORT'] = '29500'\n",
        "    dist.init_process_group(backend, rank=rank, world_size=world_size)\n",
        "    fn(rank, world_size, layer_size, update_iter, measure_iter)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"hello\")\n",
        "    W = 4\n",
        "    L = 2\n",
        "    N = 6\n",
        "    processes = []\n",
        "    st = time.time()\n",
        "    for rank in range(W):\n",
        "        p = mp.Process(target=init_process, args=(rank, W, L, N, 100, parallel_train))\n",
        "        p.start()\n",
        "        processes.append(p)\n",
        "        \n",
        "    for p in processes:\n",
        "        p.join()\n",
        "        \n",
        "    print('Implementation time : ', time.time()-st)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3m2fhrjrJ8j",
        "outputId": "f9d9ae72-3afe-4be0-8e31-ff4a30ca705f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "I am I am I am I am    2 01\n",
            "3\n",
            "\n",
            "\n",
            "tensor([[-5.3357e+01, -6.1393e-06, -5.5730e-06],\n",
            "        [-6.1393e-06, -5.3357e+01, -7.4804e-06],\n",
            "        [-5.5730e-06, -7.4804e-06,  0.0000e+00]])\n",
            "tensor([[-5.3357e+01, -4.1127e-06, -6.6757e-06],\n",
            "        [-4.1127e-06, -5.3357e+01, -2.4438e-06],\n",
            "        [-6.6757e-06, -2.4438e-06,  0.0000e+00]])\n",
            "tensor([[-5.3357e+01, -1.2070e-05, -9.1791e-06],\n",
            "        [-1.2070e-05, -5.3357e+01, -1.0043e-05],\n",
            "        [-9.1791e-06, -1.0043e-05,  0.0000e+00]])\n",
            "tensor([[-5.3357e+01, -8.1956e-06, -6.4373e-06],\n",
            "        [-8.1956e-06, -5.3357e+01, -9.7454e-06],\n",
            "        [-6.4373e-06, -9.7454e-06,  0.0000e+00]])\n",
            "tensor([[-1.5965e+02, -1.7494e-05,  3.2973e-01],\n",
            "        [-1.7494e-05, -1.5965e+02,  3.5117e-01],\n",
            "        [ 3.2973e-01,  3.5117e-01,  0.0000e+00]])\n",
            "tensor([[18.1630, -0.8389, -2.0307],\n",
            "        [-0.8389, 15.6359,  7.7572],\n",
            "        [-2.0307,  7.7572,  0.0000]])\n",
            "tensor([[ 1.4280e+01,  1.1921e-07, -1.7583e-06],\n",
            "        [ 1.1921e-07,  1.4280e+01,  2.4140e-06],\n",
            "        [-1.7583e-06,  2.4140e-06,  0.0000e+00]])\n",
            "tensor([[ 1.4280e+01,  4.2617e-06,  0.0000e+00],\n",
            "        [ 4.2617e-06,  1.4280e+01, -3.2783e-07],\n",
            "        [ 0.0000e+00, -3.2783e-07,  0.0000e+00]])\n",
            "tensor([[ 1.4280e+01, -1.4305e-06, -8.0466e-07],\n",
            "        [-1.4305e-06,  1.4280e+01, -2.2352e-06],\n",
            "        [-8.0466e-07, -2.2352e-06,  0.0000e+00]])\n",
            "tensor([[1.4280e+01, 2.9802e-07, 3.4571e-06],\n",
            "        [2.9802e-07, 1.4280e+01, 3.5763e-07],\n",
            "        [3.4571e-06, 3.5763e-07, 0.0000e+00]])\n",
            "tensor([[1.4280e+01, 2.2650e-06, 2.2054e-06],\n",
            "        [2.2650e-06, 1.4280e+01, 2.7418e-06],\n",
            "        [2.2054e-06, 2.7418e-06, 0.0000e+00]])\n",
            "tensor([[ 5.7543e+01,  1.0073e-05, -7.4615e+00],\n",
            "        [ 1.0073e-05,  5.7543e+01,  1.1042e-01],\n",
            "        [-7.4615e+00,  1.1042e-01,  0.0000e+00]])\n",
            "tensor([[-5.7487e+01, -3.9637e-06,  3.8743e-07],\n",
            "        [-3.9637e-06, -5.7487e+01, -1.4901e-06],\n",
            "        [ 3.8743e-07, -1.4901e-06,  0.0000e+00]])\n",
            "tensor([[-5.7487e+01, -6.8247e-06, -1.6093e-06],\n",
            "        [-6.8247e-06, -5.7487e+01, -2.5332e-06],\n",
            "        [-1.6093e-06, -2.5332e-06,  0.0000e+00]])\n",
            "tensor([[-5.7487e+01, -4.7386e-06, -4.2021e-06],\n",
            "        [-4.7386e-06, -5.7487e+01, -4.7684e-07],\n",
            "        [-4.2021e-06, -4.7684e-07,  0.0000e+00]])\n",
            "tensor([[-5.7487e+01, -2.0564e-06, -2.0564e-06],\n",
            "        [-2.0564e-06, -5.7487e+01, -1.1325e-06],\n",
            "        [-2.0564e-06, -1.1325e-06,  0.0000e+00]])\n",
            "tensor([[-5.7308e+01, -1.1057e-05,  1.2085e-02],\n",
            "        [-1.1057e-05, -5.7308e+01, -4.5100e-02],\n",
            "        [ 1.2085e-02, -4.5100e-02,  0.0000e+00]])\n",
            "tensor([[-50.6625,  -0.1444,  30.0119],\n",
            "        [ -0.1444, -50.6898,  -5.1759],\n",
            "        [ 30.0119,  -5.1759,   0.0000]])\n",
            "tensor([[-4.2295e+01, -8.4639e-06, -5.4240e-06],\n",
            "        [-8.4639e-06, -4.2295e+01, -2.3842e-06],\n",
            "        [-5.4240e-06, -2.3842e-06,  0.0000e+00]])\n",
            "tensor([[-4.2295e+01, -7.7486e-06, -7.7784e-06],\n",
            "        [-7.7486e-06, -4.2295e+01, -4.9770e-06],\n",
            "        [-7.7784e-06, -4.9770e-06,  0.0000e+00]])\n",
            "tensor([[-4.2295e+01, -1.1057e-05, -1.7494e-05],\n",
            "        [-1.1057e-05, -4.2295e+01, -1.2100e-05],\n",
            "        [-1.7494e-05, -1.2100e-05,  0.0000e+00]])\n",
            "tensor([[-4.2295e+01, -8.4341e-06, -7.6592e-06],\n",
            "        [-8.4341e-06, -4.2295e+01, -1.1504e-05],\n",
            "        [-7.6592e-06, -1.1504e-05,  0.0000e+00]])\n",
            "tensor([[-4.2295e+01, -1.4901e-05, -8.1956e-06],\n",
            "        [-1.4901e-05, -4.2295e+01, -9.6262e-06],\n",
            "        [-8.1956e-06, -9.6262e-06,  0.0000e+00]])\n",
            "tensor([[ 4.4009e+01,  7.3314e-06, -2.0979e+01],\n",
            "        [ 7.3314e-06,  4.4009e+01,  5.5103e+01],\n",
            "        [-2.0979e+01,  5.5103e+01,  0.0000e+00]])\n",
            "tensor([[3.5043e+01, 8.1360e-06, 1.0669e-05],\n",
            "        [8.1360e-06, 3.5043e+01, 9.5665e-06],\n",
            "        [1.0669e-05, 9.5665e-06, 0.0000e+00]])\n",
            "tensor([[ 3.5043e+01,  9.5963e-06,  3.8743e-07],\n",
            "        [ 9.5963e-06,  3.5043e+01, -8.9407e-08],\n",
            "        [ 3.8743e-07, -8.9407e-08,  0.0000e+00]])\n",
            "tensor([[3.5043e+01, 5.7518e-06, 1.9968e-06],\n",
            "        [5.7518e-06, 3.5043e+01, 3.8147e-06],\n",
            "        [1.9968e-06, 3.8147e-06, 0.0000e+00]])\n",
            "tensor([[3.5043e+01, 8.2850e-06, 5.9307e-06],\n",
            "        [8.2850e-06, 3.5043e+01, 2.4140e-06],\n",
            "        [5.9307e-06, 2.4140e-06, 0.0000e+00]])\n",
            "tensor([[3.5031e+01, 1.6987e-06, 9.6509e-01],\n",
            "        [1.6987e-06, 3.5031e+01, 1.1071e+00],\n",
            "        [9.6509e-01, 1.1071e+00, 0.0000e+00]])\n",
            "tensor([[ 2.2450e+01,  3.5465e-06,  1.5533e+02],\n",
            "        [ 3.5465e-06,  1.3003e+01, -1.2577e-05],\n",
            "        [ 1.5533e+02, -1.2577e-05,  0.0000e+00]])\n",
            "tensor([[ 1.8067e+01,  5.9605e-07,  1.7583e-06],\n",
            "        [ 5.9605e-07,  1.8067e+01, -2.5332e-06],\n",
            "        [ 1.7583e-06, -2.5332e-06,  0.0000e+00]])\n",
            "tensor([[1.8067e+01, 2.7418e-06, 1.0729e-06],\n",
            "        [2.7418e-06, 1.8067e+01, 1.6093e-06],\n",
            "        [1.0729e-06, 1.6093e-06, 0.0000e+00]])\n",
            "tensor([[1.8067e+01, 2.7716e-06, 1.5795e-06],\n",
            "        [2.7716e-06, 1.8067e+01, 2.9802e-06],\n",
            "        [1.5795e-06, 2.9802e-06, 0.0000e+00]])\n",
            "tensor([[1.8067e+01, 1.3113e-06, 1.1921e-07],\n",
            "        [1.3113e-06, 1.8067e+01, 1.9073e-06],\n",
            "        [1.1921e-07, 1.9073e-06, 0.0000e+00]])\n",
            "tensor([[1.8067e+01, 4.1127e-06, 1.6689e-06],\n",
            "        [4.1127e-06, 1.8067e+01, 1.0133e-06],\n",
            "        [1.6689e-06, 1.0133e-06, 0.0000e+00]])\n",
            "tensor([[ 5.0698e+01,  6.9141e-06, -3.6346e-01],\n",
            "        [ 6.9141e-06,  5.0698e+01, -5.0290e+00],\n",
            "        [-3.6346e-01, -5.0290e+00,  0.0000e+00]])\n",
            "tensor([[4.9795e+01, 7.3016e-06, 1.2010e-05],\n",
            "        [7.3016e-06, 4.9795e+01, 1.5140e-05],\n",
            "        [1.2010e-05, 1.5140e-05, 0.0000e+00]])\n",
            "tensor([[4.9795e+01, 1.0312e-05, 1.6093e-06],\n",
            "        [1.0312e-05, 4.9795e+01, 7.5698e-06],\n",
            "        [1.6093e-06, 7.5698e-06, 0.0000e+00]])\n",
            "tensor([[4.9795e+01, 4.0829e-06, 7.7486e-06],\n",
            "        [4.0829e-06, 4.9795e+01, 4.7982e-06],\n",
            "        [7.7486e-06, 4.7982e-06, 0.0000e+00]])\n",
            "tensor([[4.9795e+01, 1.7583e-06, 1.0759e-05],\n",
            "        [1.7583e-06, 4.9795e+01, 4.7684e-06],\n",
            "        [1.0759e-05, 4.7684e-06, 0.0000e+00]])\n",
            "tensor([[ 4.9794e+01,  5.1260e-06, -2.2221e-02],\n",
            "        [ 5.1260e-06,  4.9794e+01, -3.0748e-01],\n",
            "        [-2.2221e-02, -3.0748e-01,  0.0000e+00]])\n",
            "tensor([[ 5.0689e+01,  2.8014e-06,  5.7999e+00],\n",
            "        [ 2.8014e-06,  4.8759e+01, -4.7773e-05],\n",
            "        [ 5.7999e+00, -4.7773e-05,  0.0000e+00]])\n",
            "tensor([[-5.0689e+01, -6.7651e-06, -2.0862e-06],\n",
            "        [-6.7651e-06, -5.0689e+01, -1.0043e-05],\n",
            "        [-2.0862e-06, -1.0043e-05,  0.0000e+00]])\n",
            "tensor([[-5.0689e+01, -2.0266e-06,  5.4538e-06],\n",
            "        [-2.0266e-06, -5.0689e+01,  3.4869e-06],\n",
            "        [ 5.4538e-06,  3.4869e-06,  0.0000e+00]])\n",
            "tensor([[-5.0689e+01, -1.1921e-06,  7.2718e-06],\n",
            "        [-1.1921e-06, -5.0689e+01,  6.3777e-06],\n",
            "        [ 7.2718e-06,  6.3777e-06,  0.0000e+00]])\n",
            "tensor([[-5.0689e+01, -1.0580e-05, -9.3281e-06],\n",
            "        [-1.0580e-05, -5.0689e+01, -9.1791e-06],\n",
            "        [-9.3281e-06, -9.1791e-06,  0.0000e+00]])\n",
            "tensor([[-5.0689e+01,  8.9407e-07, -3.9637e-06],\n",
            "        [ 8.9407e-07, -5.0689e+01, -4.6790e-06],\n",
            "        [-3.9637e-06, -4.6790e-06,  0.0000e+00]])\n",
            "tensor([[-5.0698e+01,  0.0000e+00,  4.9461e+00],\n",
            "        [ 0.0000e+00, -5.0698e+01,  3.9381e-04],\n",
            "        [ 4.9461e+00,  3.9381e-04,  0.0000e+00]])\n",
            "tensor([[-5.0698e+01, -4.5896e-06, -9.2089e-06],\n",
            "        [-4.5896e-06, -5.0698e+01, -7.7784e-06],\n",
            "        [-9.2089e-06, -7.7784e-06,  0.0000e+00]])\n",
            "tensor([[-5.0698e+01, -3.8147e-06, -5.0366e-06],\n",
            "        [-3.8147e-06, -5.0698e+01, -4.5002e-06],\n",
            "        [-5.0366e-06, -4.5002e-06,  0.0000e+00]])\n",
            "tensor([[-5.0698e+01, -9.7156e-06, -1.0103e-05],\n",
            "        [-9.7156e-06, -5.0698e+01, -5.3942e-06],\n",
            "        [-1.0103e-05, -5.3942e-06,  0.0000e+00]])\n",
            "tensor([[-5.0698e+01, -1.6779e-05, -1.3083e-05],\n",
            "        [-1.6779e-05, -5.0698e+01, -1.0192e-05],\n",
            "        [-1.3083e-05, -1.0192e-05,  0.0000e+00]])\n",
            "tensor([[-5.0698e+01, -9.9540e-06,  1.6987e-05],\n",
            "        [-9.9540e-06, -5.0698e+01,  2.4319e-04],\n",
            "        [ 1.6987e-05,  2.4319e-04,  0.0000e+00]])\n",
            "tensor([[ 5.0698e+01, -2.4047e-04, -2.9365e+01],\n",
            "        [-2.4047e-04,  5.0699e+01, -9.8437e-03],\n",
            "        [-2.9365e+01, -9.8437e-03,  0.0000e+00]])\n",
            "tensor([[-5.0690e+01, -1.1027e-06,  6.2585e-07],\n",
            "        [-1.1027e-06, -5.0690e+01, -1.9670e-06],\n",
            "        [ 6.2585e-07, -1.9670e-06,  0.0000e+00]])\n",
            "tensor([[-5.0690e+01, -2.2054e-06,  1.9073e-06],\n",
            "        [-2.2054e-06, -5.0690e+01, -5.9605e-06],\n",
            "        [ 1.9073e-06, -5.9605e-06,  0.0000e+00]])\n",
            "tensor([[-5.0690e+01, -6.9141e-06, -1.0282e-05],\n",
            "        [-6.9141e-06, -5.0690e+01, -8.9109e-06],\n",
            "        [-1.0282e-05, -8.9109e-06,  0.0000e+00]])\n",
            "tensor([[-5.0690e+01, -4.0531e-06, -9.8944e-06],\n",
            "        [-4.0531e-06, -5.0690e+01, -1.1027e-05],\n",
            "        [-9.8944e-06, -1.1027e-05,  0.0000e+00]])\n",
            "tensor([[-5.0690e+01, -1.0967e-05, -7.6294e-06],\n",
            "        [-1.0967e-05, -5.0690e+01, -7.7486e-06],\n",
            "        [-7.6294e-06, -7.7486e-06,  0.0000e+00]])\n",
            "tensor([[-5.0690e+01, -1.0967e-05, -1.7466e+00],\n",
            "        [-1.0967e-05, -5.0690e+01,  1.4439e+00],\n",
            "        [-1.7466e+00,  1.4439e+00,  0.0000e+00]])\n",
            "tensor([[-8.1907e+00, -6.5565e-07,  3.5763e-07],\n",
            "        [-6.5565e-07, -8.1907e+00,  1.6093e-06],\n",
            "        [ 3.5763e-07,  1.6093e-06,  0.0000e+00]])\n",
            "tensor([[-8.1907e+00,  2.7418e-06, -6.5565e-07],\n",
            "        [ 2.7418e-06, -8.1907e+00,  2.5630e-06],\n",
            "        [-6.5565e-07,  2.5630e-06,  0.0000e+00]])\n",
            "tensor([[-8.1907e+00,  1.6093e-06, -1.9968e-06],\n",
            "        [ 1.6093e-06, -8.1907e+00, -5.0664e-07],\n",
            "        [-1.9968e-06, -5.0664e-07,  0.0000e+00]])\n",
            "tensor([[-8.1907e+00, -6.2585e-07, -2.0266e-06],\n",
            "        [-6.2585e-07, -8.1907e+00,  2.9802e-08],\n",
            "        [-2.0266e-06,  2.9802e-08,  0.0000e+00]])\n",
            "tensor([[-9.2127e+00, -8.6427e-07, -6.9168e-02],\n",
            "        [-8.6427e-07, -9.2127e+00, -1.5505e+00],\n",
            "        [-6.9168e-02, -1.5505e+00,  0.0000e+00]])\n",
            "tensor([[   9.4540,   -4.8210,  -13.2561],\n",
            "        [  -4.8210,    9.6111, -173.3605],\n",
            "        [ -13.2561, -173.3605,    0.0000]])\n",
            "tensor([[-1.7341e+02, -1.9997e-05, -2.6643e-05],\n",
            "        [-1.9997e-05, -1.7341e+02, -2.6971e-05],\n",
            "        [-2.6643e-05, -2.6971e-05,  0.0000e+00]])\n",
            "tensor([[-1.7341e+02, -1.2428e-05, -2.2352e-05],\n",
            "        [-1.2428e-05, -1.7341e+02, -2.2799e-05],\n",
            "        [-2.2352e-05, -2.2799e-05,  0.0000e+00]])\n",
            "tensor([[-1.7341e+02, -9.7156e-06, -1.5557e-05],\n",
            "        [-9.7156e-06, -1.7341e+02, -1.7822e-05],\n",
            "        [-1.5557e-05, -1.7822e-05,  0.0000e+00]])\n",
            "tensor([[-1.7341e+02, -2.2352e-06,  4.6790e-06],\n",
            "        [-2.2352e-06, -1.7341e+02,  2.9802e-06],\n",
            "        [ 4.6790e-06,  2.9802e-06,  0.0000e+00]])\n",
            "tensor([[-1.7341e+02, -1.2517e-05, -2.0862e-07],\n",
            "        [-1.2517e-05, -1.7341e+02,  1.0431e-06],\n",
            "        [-2.0862e-07,  1.0431e-06,  0.0000e+00]])\n",
            "tensor([[ 2.0813e-01,  2.2054e-06, -1.8802e+00],\n",
            "        [ 2.2054e-06,  2.0813e-01, -1.7669e+02],\n",
            "        [-1.8802e+00, -1.7669e+02,  0.0000e+00]])\n",
            "[tensor(-28.7434), tensor(17.5213), tensor(24.8976), tensor(-25.3492), tensor(-4.0954), tensor(-88.3447)] [tensor(-105.4908), tensor(73.9288), tensor(125.6998), tensor(-128.1143), tensor(-24.0940), tensor(-266.1917)]\n",
            "Implementation time :  149.3370041847229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pvqAwbGPtEep"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}