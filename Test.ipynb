{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1DItQvalDEWh665Y72M4QJP0vj51Swdce",
      "authorship_tag": "ABX9TyPze9oyKKfjM2WtYS0ETUHY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Izuho/senior-thesis/blob/main/Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.multiprocessing as mp\n",
        "import torch.distributed as dist\n",
        "import time\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from math import sqrt"
      ],
      "metadata": {
        "id": "egMM1KNT6zmP"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_process(rank, world_size, layer_size, update_iter, n_qubits, fn, backend='gloo'):\n",
        "    os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
        "    os.environ['MASTER_PORT'] = '29500'\n",
        "    dist.init_process_group(backend, rank=rank, world_size=world_size)\n",
        "    fn(rank, world_size, layer_size, update_iter, n_qubits)\n",
        "def parallel_train(rank, world_size, layer_size, update_iter, n_qubits):\n",
        "    print('I am ', rank)\n",
        "    train, test, train_size, test_size = data_loader(rank, world_size)\n",
        "    model = FraxClassify(n_qubits, layer_size, world_size)\n",
        "    acc = []\n",
        "    for i in range(update_iter):\n",
        "        model.fit(train=train)\n",
        "        (train_acc, test_acc), (train_score, test_score) = model.eval(train=train, test=test)\n",
        "        if rank == 0:\n",
        "            print(train_acc / train_size, test_acc / test_size, train_score, test_score)\n",
        "def data_loader(rank, world_size):\n",
        "    try:\n",
        "        test_label = torch.from_numpy(np.load('drive/MyDrive/mnist_test_Label.npy'))[0:200]\n",
        "        train_label = torch.from_numpy(np.load('drive/MyDrive/mnist_train_Label.npy'))[0:800]\n",
        "        test_feat = torch.from_numpy(np.load('drive/MyDrive/mnist_test_feat.npy'))[0:200]\n",
        "        train_feat = torch.from_numpy(np.load('drive/MyDrive/mnist_train_feat.npy'))[0:800]\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    data_len_min = len(train_feat) // world_size\n",
        "    offset = len(train_feat) % world_size\n",
        "    if rank < offset:\n",
        "        start1 = rank*(data_len_min+1)\n",
        "        end1 = start1+data_len_min+1\n",
        "    else:\n",
        "        start1 = offset*(data_len_min+1)+(rank-offset)*data_len_min\n",
        "        end1 = start1+data_len_min\n",
        "    data_len_min = len(test_feat) // world_size\n",
        "    offset = len(test_feat) % world_size\n",
        "    if rank < offset:\n",
        "        start2 = rank*(data_len_min+1)\n",
        "        end2 = start2+data_len_min+1\n",
        "    else:\n",
        "        start2 = offset*(data_len_min+1)+(rank-offset)*data_len_min\n",
        "        end2 = start2+data_len_min\n",
        "    return (train_feat[start1:end1], train_label[start1:end1]), (test_feat[start2:end2], test_label[start2:end2]), train_label.shape[0], test_label.shape[0]\n",
        "def lastbit_Z(state):\n",
        "    return 2 * (torch.norm(state[0:len(state):2])**2) - 1\n",
        "def amplitude_embedding(feat, n, n_qubits):\n",
        "    # feat : torch.tensor of 2^n_qubits elements\n",
        "    if feat.ndim == 1:\n",
        "        feat = feat.reshape(-1,).to(torch.complex64)\n",
        "        feat /= torch.norm(feat)\n",
        "    elif feat.ndim == 2:\n",
        "        feat = feat.reshape(-1,2**n,).to(torch.complex64)\n",
        "        feat = feat.transpose(0,1) / torch.norm(feat, dim=1)\n",
        "        feat = feat.transpose(0,1)\n",
        "    return feat.tile((2**(n_qubits-n),))\n",
        "def kronecker(A, B):\n",
        "    if not isinstance(A, torch.Tensor):\n",
        "        return B\n",
        "    return torch.einsum(\"ab,cd->acbd\", A, B).view(A.size(0)*B.size(0),  A.size(1)*B.size(1))\n",
        "CZ = torch.tensor([\n",
        "    [1,0,0,0],\n",
        "    [0,1,0,0], \n",
        "    [0,0,1,0], \n",
        "    [0,0,0,-1]], dtype=torch.cfloat)\n",
        "def CZ_layer(n_qubits):\n",
        "    if n_qubits == 2:\n",
        "        return CZ\n",
        "    gate1 = CZ\n",
        "    for i in range(2, n_qubits, 2):\n",
        "        if i+1 < n_qubits:\n",
        "            gate1 = kronecker(gate1, CZ)\n",
        "        else:\n",
        "            gate1 = kronecker(gate1, I)\n",
        "    gate2 = CZ\n",
        "    gate2 = kronecker(I, gate2)\n",
        "    for i in range(3, n_qubits, 2):\n",
        "        if i+1 < n_qubits:\n",
        "            gate2 = kronecker(gate2, CZ)\n",
        "        else:\n",
        "            gate2 = kronecker(gate2, I)\n",
        "    return torch.mm(gate2, gate1)\n",
        "X = torch.tensor([[0,1],[1,0]], dtype=torch.complex64)\n",
        "Y = torch.tensor([[0,-1j],[1j,0]], dtype=torch.complex64)\n",
        "Z = torch.tensor([[1,0],[0,-1]], dtype=torch.complex64)\n",
        "XY = (X+Y)/sqrt(2)\n",
        "XZ = (X+Z)/sqrt(2)\n",
        "YZ = (Y+Z)/sqrt(2)\n",
        "I = torch.eye(2, dtype=torch.complex64)\n",
        "def Frax(n):\n",
        "    n = n / torch.norm(n)\n",
        "    return n[0] * X + n[1] * Y + n[2] * Z\n",
        "def Frax_ansatz(n_qubits, param):\n",
        "    # param : torch.Tensor of (n_qubits, 3)\n",
        "    x = 1\n",
        "    for i in range(n_qubits):\n",
        "        x = kronecker(x, Frax(param[i]))\n",
        "    return torch.mm(CZ_layer(n_qubits), x)\n",
        "def replace_Frax_ansatz(n_qubits, measured_qubit, observable, param):\n",
        "    x = 1\n",
        "    for i in range(measured_qubit):\n",
        "        x = kronecker(x, Frax(param[i]))\n",
        "    if observable == 'X':\n",
        "        x = kronecker(x, X)\n",
        "    elif observable == 'Y':\n",
        "        x = kronecker(x, Y)\n",
        "    elif observable == 'Z':\n",
        "        x = kronecker(x, Z)\n",
        "    elif observable == 'XY':\n",
        "        x = kronecker(x, XY)\n",
        "    elif observable == 'XZ':\n",
        "        x = kronecker(x, XZ)\n",
        "    elif observable == 'YZ':\n",
        "        x = kronecker(x, YZ)\n",
        "    for i in range(measured_qubit+1, n_qubits):\n",
        "        x = kronecker(x, Frax(param[i]))\n",
        "    return torch.mm(CZ_layer(n_qubits), x)\n",
        "class FraxClassify():\n",
        "    def __init__(self, n_qubits, layer_size, world_size):\n",
        "        self.n_qubits = n_qubits\n",
        "        self.layer_size = layer_size\n",
        "        self.params = (torch.zeros(layer_size, n_qubits, 3) + 1/sqrt(3)).to(torch.complex64)\n",
        "        self.world_size =world_size\n",
        "    def fit(self, train):\n",
        "        params = self.params\n",
        "        train_feat, train_label = train\n",
        "        x = amplitude_embedding(train_feat, 6, self.n_qubits)\n",
        "        for a in range(self.layer_size):\n",
        "            for b in range(self.n_qubits):\n",
        "                R = torch.zeros(3,3)\n",
        "                for c in range(train_feat.shape[0]):\n",
        "                    y = x[c]\n",
        "                    for d in range(a):\n",
        "                        y = Frax_ansatz(self.n_qubits, params[d]) @ y\n",
        "                    rx = replace_Frax_ansatz(self.n_qubits, b, 'X', params[a]) @ y\n",
        "                    ry = replace_Frax_ansatz(self.n_qubits, b, 'Y', params[a]) @ y\n",
        "                    rz = replace_Frax_ansatz(self.n_qubits, b, 'Z', params[a]) @ y\n",
        "                    rxy = replace_Frax_ansatz(self.n_qubits, b, 'XY', params[a]) @ y\n",
        "                    rxz = replace_Frax_ansatz(self.n_qubits, b, 'XZ', params[a]) @ y\n",
        "                    ryz = replace_Frax_ansatz(self.n_qubits, b, 'YZ', params[a]) @ y\n",
        "                    for d in range(a+1, self.layer_size):\n",
        "                        rx = Frax_ansatz(self.n_qubits, params[d]) @ rx\n",
        "                        ry = Frax_ansatz(self.n_qubits, params[d]) @ ry       \n",
        "                        rz = Frax_ansatz(self.n_qubits, params[d]) @ rz\n",
        "                        rxy = Frax_ansatz(self.n_qubits, params[d]) @ rxy\n",
        "                        rxz = Frax_ansatz(self.n_qubits, params[d]) @ rxz        \n",
        "                        ryz = Frax_ansatz(self.n_qubits, params[d]) @ ryz                       \n",
        "                    rx = lastbit_Z(rx)\n",
        "                    ry = lastbit_Z(ry)\n",
        "                    rz = lastbit_Z(rz)\n",
        "                    rxy = lastbit_Z(rxy)\n",
        "                    rxz = lastbit_Z(rxz)\n",
        "                    ryz = lastbit_Z(ryz)                       \n",
        "                    R[0,0] += train_label[c] * 2 * rx\n",
        "                    R[0,1] += train_label[c] * (2 * rxy - rx - ry)\n",
        "                    R[0,2] += train_label[c] * (2 * rxz - rx - rz)\n",
        "                    R[1,1] += train_label[c] * 2 * ry\n",
        "                    R[1,2] += train_label[c] * (2 * ryz - ry - rz)\n",
        "                    R[2,2] += train_label[c] * 2 * rz                 \n",
        "                R[1,0] = R[0,1]\n",
        "                R[2,0] = R[0,2]\n",
        "                R[2,1] = R[1,2]\n",
        "                group = dist.new_group(range(self.world_size))\n",
        "                dist.all_reduce(R, op=dist.ReduceOp.SUM, group=group)\n",
        "                eigenvalues, eigenvectors = torch.linalg.eigh(R)\n",
        "                self.params[a, b] = eigenvectors[:, torch.argmax(eigenvalues)]\n",
        "                if dist.get_rank() == 0: print(torch.max(eigenvalues))\n",
        "    def eval(self, train, test):\n",
        "        group = dist.new_group(range(self.world_size))\n",
        "        cri = torch.zeros(4)\n",
        "        train_feat, train_label = train\n",
        "        test_feat, test_label = test\n",
        "        train_size = train_label.shape[0]\n",
        "        test_size = test_label.shape[0]\n",
        "        for a in range(test_size):\n",
        "            x = amplitude_embedding(test_feat[a], 6, self.n_qubits)\n",
        "            for b in range(self.layer_size):\n",
        "                x = Frax_ansatz(self.n_qubits, self.params[b]) @ x\n",
        "            if test_label[a] * lastbit_Z(x) > 0:\n",
        "                cri[1] += 1\n",
        "            cri[3] += test_label[a] * lastbit_Z(x)\n",
        "        for a in range(train_size):\n",
        "            x = amplitude_embedding(train_feat[a], 6, self.n_qubits)\n",
        "            for b in range(self.layer_size):\n",
        "                x = Frax_ansatz(self.n_qubits, self.params[b]) @ x\n",
        "            if train_label[a] * lastbit_Z(x) > 0:\n",
        "                cri[0] += 1\n",
        "            cri[2] += train_label[a] * lastbit_Z(x)\n",
        "        dist.all_reduce(cri, op=dist.ReduceOp.SUM, group=group)\n",
        "        return (cri[0], cri[1]), (2*cri[2], 2*cri[3])"
      ],
      "metadata": {
        "id": "o6CZ1_im7ZYB"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = 20 # World_size\n",
        "L = 2 # Layer_size\n",
        "N = 5 # Iteration_size\n",
        "Q = 6 # N_qubits"
      ],
      "metadata": {
        "id": "NYAXKqwM67uW"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIkwCDsi6qmJ",
        "outputId": "0b50d7f7-168f-402b-8d72-d29d1909bf02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am I am I am   1I am \n",
            " I am 0\n",
            " I am I am I am  I am I am I am 9I am I am I am 8\n",
            "  10 I am I am I am I am  \n",
            "    I am I am 13712 \n",
            " \n",
            "4 \n",
            " 311172 1415  \n",
            "\n",
            "\n",
            "516\n",
            "6\n",
            "19\n",
            "\n",
            "\n",
            "18\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tensor(-208.4319)\n",
            "tensor(-208.4319)\n",
            "tensor(-208.4319)\n",
            "tensor(-208.4319)\n",
            "tensor(777.6494)\n",
            "tensor(807.7505)\n",
            "tensor(807.7506)\n",
            "tensor(807.7508)\n",
            "tensor(807.7507)\n",
            "tensor(807.7506)\n",
            "tensor(807.7506)\n",
            "tensor(815.2742)\n",
            "tensor(0.9287) tensor(0.9150) tensor(815.2738) tensor(259.8004)\n",
            "tensor(815.2740)\n",
            "tensor(815.2742)\n",
            "tensor(815.2739)\n",
            "tensor(815.2741)\n",
            "tensor(815.6616)\n",
            "tensor(816.5688)\n",
            "tensor(816.5691)\n",
            "tensor(816.5688)\n",
            "tensor(816.5690)\n",
            "tensor(816.5693)\n",
            "tensor(816.5693)\n",
            "tensor(817.1424)\n",
            "tensor(0.9287) tensor(0.9150) tensor(817.1423) tensor(260.0410)\n",
            "tensor(817.1426)\n",
            "tensor(817.1426)\n",
            "tensor(817.1425)\n",
            "tensor(817.1426)\n",
            "tensor(817.1461)\n",
            "tensor(817.7001)\n",
            "tensor(817.7001)\n",
            "tensor(817.7001)\n",
            "tensor(817.7001)\n",
            "tensor(817.6998)\n",
            "tensor(817.7000)\n",
            "tensor(818.2416)\n",
            "tensor(0.9275) tensor(0.9150) tensor(818.2411) tensor(260.1296)\n",
            "tensor(818.2415)\n",
            "tensor(818.2414)\n",
            "tensor(818.2419)\n",
            "tensor(818.2416)\n",
            "tensor(818.2412)\n",
            "tensor(818.7716)\n",
            "tensor(818.7719)\n",
            "tensor(818.7719)\n",
            "tensor(818.7719)\n",
            "tensor(818.7717)\n",
            "tensor(818.7718)\n",
            "tensor(819.2886)\n",
            "tensor(0.9275) tensor(0.9150) tensor(819.2883) tensor(260.2121)\n",
            "tensor(819.2883)\n",
            "tensor(819.2883)\n",
            "tensor(819.2881)\n",
            "tensor(819.2884)\n",
            "tensor(819.2883)\n",
            "tensor(819.7919)\n",
            "tensor(819.7919)\n",
            "tensor(819.7920)\n",
            "tensor(819.7922)\n",
            "tensor(819.7923)\n",
            "tensor(819.7924)\n",
            "tensor(820.2809)\n",
            "tensor(0.9287) tensor(0.9150) tensor(820.2808) tensor(260.2904)\n",
            "Implementation time :  477.0666284561157\n"
          ]
        }
      ],
      "source": [
        "processes = []\n",
        "st = time.time()\n",
        "for rank in range(W):\n",
        "    p = mp.Process(target=init_process, args=(rank, W, L, N, Q, parallel_train))\n",
        "    p.start()\n",
        "    processes.append(p)\n",
        "        \n",
        "for p in processes:\n",
        "    p.join()\n",
        "        \n",
        "print('Implementation time : ', time.time()-st)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6LzGVf7G-noG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}