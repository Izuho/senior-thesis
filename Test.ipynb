{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch.multiprocessing as mp\n",
        "import torch.distributed as dist\n",
        "import time\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from math import sqrt"
      ],
      "metadata": {
        "id": "egMM1KNT6zmP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.displaypub import CapturingDisplayPublisher\n",
        "def init_process(rank, world_size, layer_size, update_iter, fn, backend='gloo'):\n",
        "    os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
        "    os.environ['MASTER_PORT'] = '29500'\n",
        "    dist.init_process_group(backend, rank=rank, world_size=world_size)\n",
        "    fn(rank, world_size, layer_size, update_iter)\n",
        "def parallel_train(rank, world_size, layer_size, update_iter):\n",
        "    print('I am ', rank)\n",
        "    n_qubits = 6\n",
        "    train, test, train_size, test_size = data_loader(rank, world_size)\n",
        "    model = FraxClassify(n_qubits, layer_size, world_size)\n",
        "    acc = []\n",
        "    for i in range(update_iter):\n",
        "        model.fit(train=train)\n",
        "        (train_acc, test_acc), (train_score, test_score) = model.eval(train=train, test=test)\n",
        "        if rank == 0:\n",
        "            print(train_acc / train_size, test_acc / test_size, train_score, test_score)\n",
        "def data_loader(rank, world_size):\n",
        "    try:\n",
        "        test_label = torch.from_numpy(np.load('drive/MyDrive/mnist_test_Label.npy'))\n",
        "        train_label = torch.from_numpy(np.load('drive/MyDrive/mnist_train_Label.npy'))\n",
        "        test_feat = torch.from_numpy(np.load('drive/MyDrive/mnist_test_feat.npy'))\n",
        "        train_feat = torch.from_numpy(np.load('drive/MyDrive/mnist_train_feat.npy'))\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    data_len_min = len(train_feat) // world_size\n",
        "    offset = len(train_feat) % world_size\n",
        "    if rank < offset:\n",
        "        start1 = rank*(data_len_min+1)\n",
        "        end1 = start1+data_len_min+1\n",
        "    else:\n",
        "        start1 = offset*(data_len_min+1)+(rank-offset)*data_len_min\n",
        "        end1 = start1+data_len_min\n",
        "    data_len_min = len(test_feat) // world_size\n",
        "    offset = len(test_feat) % world_size\n",
        "    if rank < offset:\n",
        "        start2 = rank*(data_len_min+1)\n",
        "        end2 = start2+data_len_min+1\n",
        "    else:\n",
        "        start2 = offset*(data_len_min+1)+(rank-offset)*data_len_min\n",
        "        end2 = start2+data_len_min\n",
        "    return (train_feat[start1:end1], train_label[start1:end1]), (test_feat[start2:end2], test_label[start2:end2]), train_label.shape[0], test_label.shape[0]\n",
        "def lastbit_Z(state):\n",
        "    return 2 * (torch.norm(state[0:len(state):2])**2) - 1\n",
        "def amplitude_embedding(feat, n_qubits):\n",
        "    # feat : torch.tensor of 2^n_qubits elements\n",
        "    if feat.ndim == 1:\n",
        "        feat = feat.reshape(-1,).to(torch.complex64)\n",
        "        feat /= torch.norm(feat)\n",
        "    elif feat.ndim == 2:\n",
        "        feat = feat.reshape(-1, 2**n_qubits,).to(torch.complex64)\n",
        "        feat = feat.transpose(0,1) / torch.norm(feat, dim=1)\n",
        "        feat = feat.transpose(0,1)\n",
        "    return feat\n",
        "def kronecker(A, B):\n",
        "    if not isinstance(A, torch.Tensor):\n",
        "        return B\n",
        "    return torch.einsum(\"ab,cd->acbd\", A, B).view(A.size(0)*B.size(0),  A.size(1)*B.size(1))\n",
        "CZ = torch.tensor([\n",
        "    [1,0,0,0],\n",
        "    [0,1,0,0], \n",
        "    [0,0,1,0], \n",
        "    [0,0,0,-1]], dtype=torch.cfloat)\n",
        "def CZ_layer(n_qubits):\n",
        "    if n_qubits == 2:\n",
        "        return CZ\n",
        "    gate1 = CZ\n",
        "    for i in range(2, n_qubits, 2):\n",
        "        if i+1 < n_qubits:\n",
        "            gate1 = kronecker(gate1, CZ)\n",
        "        else:\n",
        "            gate1 = kronecker(gate1, I)\n",
        "    gate2 = CZ\n",
        "    gate2 = kronecker(I, gate2)\n",
        "    for i in range(3, n_qubits, 2):\n",
        "        if i+1 < n_qubits:\n",
        "            gate2 = kronecker(gate2, CZ)\n",
        "        else:\n",
        "            gate2 = kronecker(gate2, I)\n",
        "    return torch.mm(gate2, gate1)\n",
        "Z = torch.tensor([\n",
        "    [1.0, 0],\n",
        "    [0, -1.0]\n",
        "], dtype=torch.complex64)\n",
        "X = torch.tensor([\n",
        "    [0, 1.0],\n",
        "    [1.0,  0]\n",
        "], dtype=torch.complex64)\n",
        "Y = torch.tensor([\n",
        "    [0, -1.0j],\n",
        "    [1.0j, 0]\n",
        "], dtype=torch.complex64)\n",
        "I = torch.eye(2, dtype=torch.complex64)\n",
        "def Frax(n):\n",
        "    n = n / torch.norm(n)\n",
        "    return n[0] * X + n[1] * Y + n[2] * Z\n",
        "def Frax_ansatz(n_qubits, param):\n",
        "    # param : torch.Tensor of (n_qubits, 3)\n",
        "    x = 1\n",
        "    for i in range(n_qubits):\n",
        "        x = kronecker(x, Frax(param[i]))\n",
        "    return torch.mm(CZ_layer(n_qubits), x)\n",
        "def replace_Frax_ansatz(n_qubits, measured_qubit, observable, param):\n",
        "    x = 1\n",
        "    for i in range(measured_qubit):\n",
        "        x = kronecker(x, Frax(param[i]))\n",
        "    if observable == 'X':\n",
        "        x = kronecker(x, X)\n",
        "    elif observable == 'Y':\n",
        "        x = kronecker(x, Y)\n",
        "    elif observable == 'Z':\n",
        "        x = kronecker(x, Z)\n",
        "    elif observable == 'XY':\n",
        "        x = kronecker(x, (X+Y)/sqrt(2))\n",
        "    elif observable == 'XZ':\n",
        "        x = kronecker(x, (X+Z)/sqrt(2))\n",
        "    elif observable == 'YZ':\n",
        "        x = kronecker(x, (Y+Z)/sqrt(2))\n",
        "    for i in range(measured_qubit+1, n_qubits):\n",
        "        x = kronecker(x, Frax(param[i]))\n",
        "    return torch.mm(CZ_layer(n_qubits), x)\n",
        "class FraxClassify():\n",
        "    def __init__(self, n_qubits, layer_size, world_size):\n",
        "        self.n_qubits = n_qubits\n",
        "        self.layer_size = layer_size\n",
        "        self.params = (torch.zeros(layer_size, n_qubits, 3) + 1/sqrt(3)).to(torch.complex64)\n",
        "        self.world_size =world_size\n",
        "        self.train_acc = []\n",
        "        self.test_acc = []    \n",
        "    def fit(self, train):\n",
        "        params = self.params\n",
        "        train_feat, train_label = train\n",
        "        x = amplitude_embedding(train_feat, self.n_qubits)\n",
        "        for a in range(self.layer_size):\n",
        "            for b in range(self.n_qubits):\n",
        "                R = torch.zeros(3,3)\n",
        "                for c in range(train_feat.shape[0]):\n",
        "                    y = x[c]\n",
        "                    for d in range(a):\n",
        "                        y = Frax_ansatz(self.n_qubits, params[d]) @ y\n",
        "                    rx = replace_Frax_ansatz(self.n_qubits, b, 'X', params[a]) @ y\n",
        "                    ry = replace_Frax_ansatz(self.n_qubits, b, 'Y', params[a]) @ y\n",
        "                    rz = replace_Frax_ansatz(self.n_qubits, b, 'Z', params[a]) @ y\n",
        "                    rxy = replace_Frax_ansatz(self.n_qubits, b, 'XY', params[a]) @ y\n",
        "                    rxz = replace_Frax_ansatz(self.n_qubits, b, 'XZ', params[a]) @ y\n",
        "                    ryz = replace_Frax_ansatz(self.n_qubits, b, 'YZ', params[a]) @ y\n",
        "                    for d in range(a+1, self.layer_size):\n",
        "                        rx = Frax_ansatz(self.n_qubits, params[d]) @ rx\n",
        "                        ry = Frax_ansatz(self.n_qubits, params[d]) @ ry       \n",
        "                        rz = Frax_ansatz(self.n_qubits, params[d]) @ rz\n",
        "                        rxy = Frax_ansatz(self.n_qubits, params[d]) @ rxy\n",
        "                        rxz = Frax_ansatz(self.n_qubits, params[d]) @ rxz        \n",
        "                        ryz = Frax_ansatz(self.n_qubits, params[d]) @ ryz                       \n",
        "                    rx = lastbit_Z(rx)\n",
        "                    ry = lastbit_Z(ry)\n",
        "                    rz = lastbit_Z(rz)\n",
        "                    rxy = lastbit_Z(rxy)\n",
        "                    rxz = lastbit_Z(rxz)\n",
        "                    ryz = lastbit_Z(ryz)                       \n",
        "                    R[0,0] += train_label[c] * 2 * rx\n",
        "                    R[0,1] += train_label[c] * (2 * rxy - rx - ry)\n",
        "                    R[0,2] += train_label[c] * (2 * rxz - rx - rz)\n",
        "                    R[1,1] += train_label[c] * 2 * ry\n",
        "                    R[1,2] += train_label[c] * (2 * ryz - ry - rz)\n",
        "                    R[2,1] += train_label[c] * 2 * rz                 \n",
        "                R[1,0] = R[0,1]\n",
        "                R[2,0] = R[0,2]\n",
        "                R[2,1] = R[1,2]\n",
        "                group = dist.new_group(range(self.world_size))\n",
        "                dist.all_reduce(R, op=dist.ReduceOp.SUM, group=group)\n",
        "                eigenvalues, eigenvectors = torch.linalg.eigh(R)\n",
        "                self.params[a, b] = eigenvectors[:, torch.argmax(eigenvalues)]\n",
        "                (vgb,_), (sgb,_) = self.eval(train,train)\n",
        "                if dist.get_rank() == 0:\n",
        "                    print(torch.max(eigenvalues))\n",
        "                    print(vgb, sgb)\n",
        "                            \n",
        "    def eval(self, train, test):\n",
        "        group = dist.new_group(range(self.world_size))\n",
        "        cri = torch.zeros(4)\n",
        "        train_feat, train_label = train\n",
        "        test_feat, test_label = test\n",
        "        train_size = train_label.shape[0]\n",
        "        test_size = test_label.shape[0]\n",
        "        for a in range(test_size):\n",
        "            x = amplitude_embedding(test_feat[a], self.n_qubits)\n",
        "            for b in range(self.layer_size):\n",
        "                x = Frax_ansatz(self.n_qubits, self.params[b]) @ x\n",
        "            if test_label[a] * lastbit_Z(x) > 0:\n",
        "                cri[1] += 1\n",
        "            cri[3] += test_label[a] * lastbit_Z(x)\n",
        "        for a in range(train_size):\n",
        "            x = amplitude_embedding(train_feat[a], self.n_qubits)\n",
        "            for b in range(self.layer_size):\n",
        "                x = Frax_ansatz(self.n_qubits, self.params[b]) @ x\n",
        "            if train_label[a] * lastbit_Z(x) > 0:\n",
        "                cri[0] += 1\n",
        "            cri[2] += train_label[a] * lastbit_Z(x)\n",
        "        dist.all_reduce(cri, op=dist.ReduceOp.SUM, group=group)\n",
        "        return (cri[0], cri[1]), (2*cri[2], 2*cri[3])"
      ],
      "metadata": {
        "id": "o6CZ1_im7ZYB"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = 4 # World_size\n",
        "L = 4 # Layer_size\n",
        "N = 10 # Iteration_size"
      ],
      "metadata": {
        "id": "NYAXKqwM67uW"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fIkwCDsi6qmJ",
        "outputId": "c2178740-349b-4f27-8f2a-ad58e6bf0530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am I am I am  I am  3\n",
            "2 \n",
            " 01\n",
            "\n",
            "tensor(1.9074e-06)\n",
            "tensor(21.) tensor(-31.0530)\n",
            "tensor(-9.5362e-07)\n",
            "tensor(21.) tensor(-31.0530)\n",
            "tensor(8.2442)\n",
            "tensor(94.) tensor(22.0340)\n",
            "tensor(30.0270)\n",
            "tensor(113.) tensor(39.0208)\n",
            "tensor(12.6113)\n",
            "tensor(115.) tensor(38.5114)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Process Process-53:\n",
            "Process Process-56:\n",
            "Traceback (most recent call last):\n",
            "Process Process-55:\n",
            "Process Process-54:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"<ipython-input-62-db211145138a>\", line 6, in init_process\n",
            "    fn(rank, world_size, layer_size, update_iter)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-62-db211145138a>\", line 6, in init_process\n",
            "    fn(rank, world_size, layer_size, update_iter)\n",
            "  File \"<ipython-input-62-db211145138a>\", line 6, in init_process\n",
            "    fn(rank, world_size, layer_size, update_iter)\n",
            "  File \"<ipython-input-62-db211145138a>\", line 14, in parallel_train\n",
            "    model.fit(train=train)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-62-db211145138a>\", line 14, in parallel_train\n",
            "    model.fit(train=train)\n",
            "  File \"<ipython-input-62-db211145138a>\", line 143, in fit\n",
            "    rz = replace_Frax_ansatz(self.n_qubits, b, 'Z', params[a]) @ y\n",
            "  File \"<ipython-input-62-db211145138a>\", line 148, in fit\n",
            "    rx = Frax_ansatz(self.n_qubits, params[d]) @ rx\n",
            "  File \"<ipython-input-62-db211145138a>\", line 106, in replace_Frax_ansatz\n",
            "    x = kronecker(x, Frax(param[i]))\n",
            "  File \"<ipython-input-62-db211145138a>\", line 101, in Frax_ansatz\n",
            "    x = kronecker(x, Frax(param[i]))\n",
            "  File \"<ipython-input-62-db211145138a>\", line 95, in Frax\n",
            "    n = n / torch.norm(n)\n",
            "  File \"<ipython-input-62-db211145138a>\", line 58, in kronecker\n",
            "    return torch.einsum(\"ab,cd->acbd\", A, B).view(A.size(0)*B.size(0),  A.size(1)*B.size(1))\n",
            "  File \"<ipython-input-62-db211145138a>\", line 14, in parallel_train\n",
            "    model.fit(train=train)\n",
            "KeyboardInterrupt\n",
            "  File \"<ipython-input-62-db211145138a>\", line 6, in init_process\n",
            "    fn(rank, world_size, layer_size, update_iter)\n",
            "  File \"<ipython-input-62-db211145138a>\", line 144, in fit\n",
            "    rxy = replace_Frax_ansatz(self.n_qubits, b, 'XY', params[a]) @ y\n",
            "  File \"<ipython-input-62-db211145138a>\", line 14, in parallel_train\n",
            "    model.fit(train=train)\n",
            "  File \"<ipython-input-62-db211145138a>\", line 106, in replace_Frax_ansatz\n",
            "    x = kronecker(x, Frax(param[i]))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/functional.py\", line 360, in einsum\n",
            "    return _VF.einsum(equation, operands)  # type: ignore[attr-defined]\n",
            "KeyboardInterrupt\n",
            "KeyboardInterrupt\n",
            "  File \"<ipython-input-62-db211145138a>\", line 150, in fit\n",
            "    rz = Frax_ansatz(self.n_qubits, params[d]) @ rz\n",
            "  File \"<ipython-input-62-db211145138a>\", line 102, in Frax_ansatz\n",
            "    return torch.mm(CZ_layer(n_qubits), x)\n",
            "  File \"<ipython-input-62-db211145138a>\", line 80, in CZ_layer\n",
            "    return torch.mm(gate2, gate1)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-98ceabe26156>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Implementation time : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "processes = []\n",
        "st = time.time()\n",
        "for rank in range(W):\n",
        "    p = mp.Process(target=init_process, args=(rank, W, L, N, parallel_train))\n",
        "    p.start()\n",
        "    processes.append(p)\n",
        "        \n",
        "for p in processes:\n",
        "    p.join()\n",
        "        \n",
        "print('Implementation time : ', time.time()-st)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = torch.tensor([[-7.4738e-01+0.j, -6.6439e-01+0.j, -1.3709e-06+0.j],\n",
        "         [ 7.2640e-01+0.j,  6.8727e-01+0.j,  1.5497e-06+0.j],\n",
        "         [ 5.3045e-01+0.j,  8.4772e-01+0.j,  1.6689e-06+0.j],\n",
        "         [-6.5305e-01+0.j, -7.5731e-01+0.j, -1.0133e-06+0.j],\n",
        "         [ 6.8999e-01+0.j,  7.2382e-01+0.j,  1.4305e-06+0.j],\n",
        "         [ 4.1626e-01+0.j,  7.7486e-07+0.j,  9.0925e-01+0.j]])\n",
        "(train_feat, train_label), _, _, _ = data_loader(0, 1)\n",
        "x = amplitude_embedding(train_feat, 6)\n",
        "R = torch.zeros(3,3)\n",
        "cccc = 5\n",
        "for c in range(train_feat.shape[0]):\n",
        "    y = x[c]\n",
        "    rx = lastbit_Z(replace_Frax_ansatz(6, cccc, 'X', v) @ y)\n",
        "    ry = lastbit_Z(replace_Frax_ansatz(6, cccc, 'Y', v) @ y)\n",
        "    rz = lastbit_Z(replace_Frax_ansatz(6, cccc, 'Z', v) @ y)\n",
        "    rxy = lastbit_Z(replace_Frax_ansatz(6, cccc, 'XY', v) @ y)\n",
        "    rxz = lastbit_Z(replace_Frax_ansatz(6, cccc, 'XZ', v) @ y)\n",
        "    ryz = lastbit_Z(replace_Frax_ansatz(6, cccc, 'YZ', v) @ y)\n",
        "                                          \n",
        "    R[0,0] += train_label[c] * 2 * rx\n",
        "    R[0,1] += train_label[c] * (2 * rxy - rx - ry)\n",
        "    R[0,2] += train_label[c] * (2 * rxz - rx - rz)\n",
        "    R[1,1] += train_label[c] * 2 * ry\n",
        "    R[1,2] += train_label[c] * (2 * ryz - ry - rz)\n",
        "    R[2,1] += train_label[c] * 2 * rz                 \n",
        "R[1,0] = R[0,1]\n",
        "R[2,0] = R[0,2]\n",
        "R[2,1] = R[1,2]\n",
        "                \n",
        "eigenvalues, eigenvectors = torch.linalg.eigh(R)\n",
        "print(eigenvalues)\n",
        "print(eigenvectors)\n",
        "print(torch.dot(eigenvectors[:,2], torch.mv(R, eigenvectors[:,2])))\n",
        "score = 0\n",
        "w = v\n",
        "w[cccc] = eigenvectors[:,2]\n",
        "for c in range(train_feat.shape[0]):\n",
        "    y = x[c]\n",
        "    score += train_label[c] * lastbit_Z(Frax_ansatz(6, w) @ y)\n",
        "print(2*score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uha7vGwAI3R0",
        "outputId": "57772e79-894d-4b56-fa96-69d46da2b44b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-64.1412, -50.6982,  13.4429])\n",
            "tensor([[ 9.0925e-01, -3.8973e-07,  4.1626e-01],\n",
            "        [-8.0466e-07, -1.0000e+00,  7.7486e-07],\n",
            "        [-4.1626e-01,  1.0729e-06,  9.0925e-01]])\n",
            "tensor(13.4429)\n",
            "tensor(55.3568)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M=100\n",
        "nrand = torch.rand(M, 3)\n",
        "maxscore = 0\n",
        "for i in range(M):\n",
        "    cb = nrand[i] / torch.norm(nrand[i])\n",
        "    if maxscore < torch.dot(cb, torch.mv(R, cb)):\n",
        "        maxscore = torch.dot(cb, torch.mv(R, cb))\n",
        "print(maxscore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxqtVXDNOPrV",
        "outputId": "a1fa0606-fb65-400a-a2fb-2ed8928fec98"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(12.6407)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uyIGu7AJTD86"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}