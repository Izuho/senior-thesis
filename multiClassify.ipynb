{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Izuho/senior-thesis/blob/main/multiClassify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F0h44n6lLdIR"
      },
      "outputs": [],
      "source": [
        "import torch.multiprocessing as mp\n",
        "import torch.distributed as dist\n",
        "import time\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "from torchvision import datasets, transforms\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MM = 4"
      ],
      "metadata": {
        "id": "0t9MZsZ9yuWP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iKWpTSb2Lsun"
      },
      "outputs": [],
      "source": [
        "mnist_train = datasets.MNIST(\n",
        "    root='./data',\n",
        "    download=True,\n",
        "    train=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        ")\n",
        "mnist_test = datasets.MNIST(\n",
        "    root='./data',\n",
        "    download=True,\n",
        "    train=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        ")\n",
        "\n",
        "x_train = mnist_train.train_data.numpy()\n",
        "y_train = mnist_train.train_labels.numpy()\n",
        "x_test = mnist_test.test_data.numpy()\n",
        "y_test = mnist_test.test_labels.numpy()\n",
        "\n",
        "x_train = x_train[np.where(y_train < MM, True, False)]\n",
        "y_train = y_train[np.where(y_train < MM, True, False)]\n",
        "x_test = x_test[np.where(y_test < MM, True, False)]\n",
        "y_test = y_test[np.where(y_test < MM, True, False)]\n",
        "\n",
        "N = x_train.shape[0]\n",
        "M = x_test.shape[0]\n",
        "new_x_train = np.zeros((N,8,8))\n",
        "new_x_test = np.zeros((M,8,8))\n",
        "for i in range(N):\n",
        "    new_x_train[i] = cv2.resize(x_train[i], (8,8), cv2.INTER_AREA)\n",
        "for i in range(M):\n",
        "    new_x_test[i] = cv2.resize(x_test[i], (8,8), cv2.INTER_AREA)\n",
        "\n",
        "new2_x_test = new_x_test.reshape(-1,64)\n",
        "new2_x_train = new_x_train.reshape(-1,64)\n",
        "\n",
        "new3_x_test = new2_x_test / np.sqrt(np.sum(new2_x_test*new2_x_test, axis = 1)).reshape(-1,1)\n",
        "new3_x_train = new2_x_train / np.sqrt(np.sum(new2_x_train*new2_x_train, axis = 1)).reshape(-1,1)\n",
        "\n",
        "save_root = './'\n",
        "if not os.path.exists(save_root):\n",
        "    os.mkdir(save_root)\n",
        "np.save(os.path.join(save_root, 'drive/MyDrive/mnist_x_train'), new3_x_train)\n",
        "np.save(os.path.join(save_root, 'drive/MyDrive/mnist_y_train'), y_train)\n",
        "np.save(os.path.join(save_root, 'drive/MyDrive/mnist_x_test'), new3_x_test)\n",
        "np.save(os.path.join(save_root, 'drive/MyDrive/mnist_y_test'), y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TR_SIZE = 800\n",
        "TE_SIZE = 200"
      ],
      "metadata": {
        "id": "xCyW612hz9W-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "cvC-ksoCMwgr"
      },
      "outputs": [],
      "source": [
        "def init_process(rank, world_size, layer_size, update_iter, Q, fn, backend='gloo'):\n",
        "    os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
        "    os.environ['MASTER_PORT'] = '29500'\n",
        "    dist.init_process_group(backend, rank=rank, world_size=world_size)\n",
        "    fn(rank, world_size, layer_size, update_iter, Q)\n",
        "def parallel_train(rank, world_size, layer_size, update_iter, Q):\n",
        "    print('I am ', rank)\n",
        "    train, test, train_size, test_size = data_loader(rank, world_size)\n",
        "    model = FraxClassify(layer_size, world_size, Q)\n",
        "    acc = []\n",
        "    for i in range(update_iter):\n",
        "        model.fit(train=train)\n",
        "        (test_acc, test_score), (train_acc, train_score) = model.eval(train=train, test=test)\n",
        "        if rank == 0:\n",
        "            print(train_acc / train_size, test_acc / test_size, train_score, test_score)\n",
        "def data_loader(rank, world_size):\n",
        "    try:\n",
        "        test_label = torch.from_numpy(np.load('drive/MyDrive/mnist_y_test.npy'))[0:TE_SIZE]\n",
        "        train_label = torch.from_numpy(np.load('drive/MyDrive/mnist_y_train.npy'))[0:TR_SIZE]\n",
        "        test_feat = torch.from_numpy(np.load('drive/MyDrive/mnist_x_test.npy'))[0:TE_SIZE]\n",
        "        train_feat = torch.from_numpy(np.load('drive/MyDrive/mnist_x_train.npy'))[0:TR_SIZE]\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    data_len_min = len(train_feat) // world_size\n",
        "    offset = len(train_feat) % world_size\n",
        "    if rank < offset:\n",
        "        start1 = rank*(data_len_min+1)\n",
        "        end1 = start1+data_len_min+1\n",
        "    else:\n",
        "        start1 = offset*(data_len_min+1)+(rank-offset)*data_len_min\n",
        "        end1 = start1+data_len_min\n",
        "    data_len_min = len(test_feat) // world_size\n",
        "    offset = len(test_feat) % world_size\n",
        "    if rank < offset:\n",
        "        start2 = rank*(data_len_min+1)\n",
        "        end2 = start2+data_len_min+1\n",
        "    else:\n",
        "        start2 = offset*(data_len_min+1)+(rank-offset)*data_len_min\n",
        "        end2 = start2+data_len_min\n",
        "    return (train_feat[start1:end1], train_label[start1:end1]), (test_feat[start2:end2], test_label[start2:end2]), train_label.shape[0], test_label.shape[0]\n",
        "def bit_Z(state, bit):\n",
        "    ans = 0\n",
        "    for i in range(2**(bit-1)):\n",
        "        ans += 2 * (torch.norm(state[i:len(state):2**bit])**2) - 1\n",
        "    return ans\n",
        "def amplitude_embedding(feat, n, n_qubits):\n",
        "    feat = feat.reshape(-1,).to(torch.complex64)\n",
        "    feat = torch.repeat_interleave(feat, 2**(n_qubits-n))\n",
        "    feat /= torch.norm(feat)\n",
        "    return feat\n",
        "def frax_embedding(feat, n, n_qubits):\n",
        "    count = 0\n",
        "    ans = torch.eye(2**n_qubits).to(torch.complex64)\n",
        "    x = 1\n",
        "    #assert 2**n % n_qubits == 0, 'Error from frax_embedding!'\n",
        "    for i in range(0, feat.shape[0], 2):\n",
        "        n = torch.zeros(3).to(torch.complex64)\n",
        "        n[0], n[1] = feat[i].to(torch.complex64), feat[i+1].to(torch.complex64)\n",
        "        n[2] = torch.sqrt(1-n[0]**2-n[1]**2)\n",
        "        x = kronecker(x, Frax(n))\n",
        "        if (count+1) % n_qubits == 0:\n",
        "            ans = CZ_layer(n_qubits) @ ans @ x\n",
        "            x = 1\n",
        "        count += 1\n",
        "    return ans\n",
        "def kronecker(A, B):\n",
        "    if not isinstance(A, torch.Tensor):\n",
        "        return B\n",
        "    return torch.einsum(\"ab,cd->acbd\", A, B).view(A.size(0)*B.size(0),  A.size(1)*B.size(1))\n",
        "CZ = torch.tensor([\n",
        "    [1,0,0,0],\n",
        "    [0,1,0,0], \n",
        "    [0,0,1,0], \n",
        "    [0,0,0,-1]], dtype=torch.cfloat)\n",
        "def CZ_layer(n_qubits):\n",
        "    if n_qubits == 2:\n",
        "        return CZ\n",
        "    gate1 = CZ\n",
        "    for i in range(2, n_qubits, 2):\n",
        "        if i+1 < n_qubits:\n",
        "            gate1 = kronecker(gate1, CZ)\n",
        "        else:\n",
        "            gate1 = kronecker(gate1, I)\n",
        "    gate2 = CZ\n",
        "    gate2 = kronecker(I, gate2)\n",
        "    for i in range(3, n_qubits, 2):\n",
        "        if i+1 < n_qubits:\n",
        "            gate2 = kronecker(gate2, CZ)\n",
        "        else:\n",
        "            gate2 = kronecker(gate2, I)\n",
        "    return torch.mm(gate2, gate1)\n",
        "X = torch.tensor([[0,1],[1,0]], dtype=torch.complex64)\n",
        "Y = torch.tensor([[0,-1j],[1j,0]], dtype=torch.complex64)\n",
        "Z = torch.tensor([[1,0],[0,-1]], dtype=torch.complex64)\n",
        "XY = (X+Y)/sqrt(2)\n",
        "XZ = (X+Z)/sqrt(2)\n",
        "YZ = (Y+Z)/sqrt(2)\n",
        "I = torch.eye(2, dtype=torch.complex64)\n",
        "def Frax(n):\n",
        "    n = n / torch.norm(n)\n",
        "    return n[0] * X + n[1] * Y + n[2] * Z\n",
        "def Frax_ansatz(n_qubits, param):\n",
        "    # param : torch.Tensor of (n_qubits, 3)\n",
        "    x = 1\n",
        "    for i in range(n_qubits):\n",
        "        x = kronecker(x, Frax(param[i]))\n",
        "    return torch.mm(CZ_layer(n_qubits), x)\n",
        "def replace_Frax_ansatz(n_qubits, measured_qubit, observable, param):\n",
        "    x = 1\n",
        "    for i in range(measured_qubit):\n",
        "        x = kronecker(x, Frax(param[i]))\n",
        "    if observable == 'X':\n",
        "        x = kronecker(x, X)\n",
        "    elif observable == 'Y':\n",
        "        x = kronecker(x, Y)\n",
        "    elif observable == 'Z':\n",
        "        x = kronecker(x, Z)\n",
        "    elif observable == 'XY':\n",
        "        x = kronecker(x, XY)\n",
        "    elif observable == 'XZ':\n",
        "        x = kronecker(x, XZ)\n",
        "    elif observable == 'YZ':\n",
        "        x = kronecker(x, YZ)\n",
        "    for i in range(measured_qubit+1, n_qubits):\n",
        "        x = kronecker(x, Frax(param[i]))\n",
        "    return torch.mm(CZ_layer(n_qubits), x)\n",
        "#converter = [[1],[-1]]\n",
        "converter = [[-1,-1],[-1,1],[1,-1],[1,1]]\n",
        "#converter = [(-1,-1,-1), (-1,-1,1), (-1,1,-1), (-1,1,1), (1,-1,-1), (1,-1,1), (1,1,-1), (1,1,1)]\n",
        "class FraxClassify():\n",
        "    def __init__(self, layer_size, world_size, Q):\n",
        "        self.layer_size = layer_size\n",
        "        self.params = (torch.zeros(layer_size, Q, 3) + 1/sqrt(3)).to(torch.complex64)\n",
        "        self.world_size = world_size\n",
        "        self.n_qubits = Q\n",
        "    def fit(self, train):\n",
        "        params = self.params\n",
        "        train_feat, train_label = train\n",
        "        for a in range(self.layer_size):\n",
        "            for b in range(self.n_qubits):\n",
        "                R = torch.zeros(3,3)\n",
        "                for c in range(train_feat.shape[0]):\n",
        "                    #y = amplitude_embedding(train_feat[c])\n",
        "                    y = frax_embedding(train_feat[c], 6, self.n_qubits)[:,0]\n",
        "                    for d in range(a):\n",
        "                        y = Frax_ansatz(self.n_qubits, params[d]) @ y\n",
        "                        y = frax_embedding(train_feat[c], 6, self.n_qubits) @ y\n",
        "                    rx = replace_Frax_ansatz(self.n_qubits, b, 'X', params[a]) @ y\n",
        "                    ry = replace_Frax_ansatz(self.n_qubits, b, 'Y', params[a]) @ y\n",
        "                    rz = replace_Frax_ansatz(self.n_qubits, b, 'Z', params[a]) @ y\n",
        "                    rxy = replace_Frax_ansatz(self.n_qubits, b, 'XY', params[a]) @ y\n",
        "                    rxz = replace_Frax_ansatz(self.n_qubits, b, 'XZ', params[a]) @ y\n",
        "                    ryz = replace_Frax_ansatz(self.n_qubits, b, 'YZ', params[a]) @ y\n",
        "                    for d in range(a+1, self.layer_size):\n",
        "                        rx = frax_embedding(train_feat[c], 6, self.n_qubits) @ rx\n",
        "                        ry = frax_embedding(train_feat[c], 6, self.n_qubits) @ ry\n",
        "                        rz = frax_embedding(train_feat[c], 6, self.n_qubits) @ rz\n",
        "                        rxy = frax_embedding(train_feat[c], 6, self.n_qubits) @ rxy\n",
        "                        rxz = frax_embedding(train_feat[c], 6, self.n_qubits) @ rxz\n",
        "                        ryz = frax_embedding(train_feat[c], 6, self.n_qubits) @ ryz\n",
        "                        rx = Frax_ansatz(self.n_qubits, params[d]) @ rx\n",
        "                        ry = Frax_ansatz(self.n_qubits, params[d]) @ ry       \n",
        "                        rz = Frax_ansatz(self.n_qubits, params[d]) @ rz\n",
        "                        rxy = Frax_ansatz(self.n_qubits, params[d]) @ rxy\n",
        "                        rxz = Frax_ansatz(self.n_qubits, params[d]) @ rxz        \n",
        "                        ryz = Frax_ansatz(self.n_qubits, params[d]) @ ryz\n",
        "                    '''               \n",
        "                    rxs = (bit_Z(rx, 1), bit_Z(rx, 3), bit_Z(rx, 5))\n",
        "                    rys = (bit_Z(ry, 1), bit_Z(ry, 3), bit_Z(ry, 5))\n",
        "                    rzs = (bit_Z(rz, 1), bit_Z(rz, 3), bit_Z(rz, 5))\n",
        "                    rxys = (bit_Z(rxy, 1), bit_Z(rxy, 3), bit_Z(rxy, 5))\n",
        "                    rxzs = (bit_Z(rxz, 1), bit_Z(rxz, 3), bit_Z(rxz, 5))\n",
        "                    ryzs = (bit_Z(ryz, 1), bit_Z(ryz, 3), bit_Z(ryz, 5))\n",
        "                    '''\n",
        "                    rxs = [bit_Z(rx, 1), bit_Z(rx, 6)]\n",
        "                    rys = [bit_Z(ry, 1), bit_Z(ry, 6)]\n",
        "                    rzs = [bit_Z(rz, 1), bit_Z(rz, 6)]\n",
        "                    rxys = [bit_Z(rxy, 1), bit_Z(rxy, 6)]\n",
        "                    rxzs = [bit_Z(rxz, 1), bit_Z(rxz, 6)]\n",
        "                    ryzs = [bit_Z(ryz, 1), bit_Z(ryz, 6)]\n",
        "                    for d in range(2):\n",
        "                    #for d in range(3):\n",
        "                        R[0,0] += converter[train_label[c]][d] * 2 * rxs[d]\n",
        "                        R[0,1] += converter[train_label[c]][d] * (2 * rxys[d] - rxs[d] - rys[d])\n",
        "                        R[0,2] += converter[train_label[c]][d] * (2 * rxzs[d] - rxs[d] - rzs[d])\n",
        "                        R[1,1] += converter[train_label[c]][d] * 2 * rys[d]\n",
        "                        R[1,2] += converter[train_label[c]][d] * (2 * ryzs[d] - rys[d] - rzs[d])\n",
        "                        R[2,2] += converter[train_label[c]][d] * 2 * rzs[d]          \n",
        "                R[1,0] = R[0,1]\n",
        "                R[2,0] = R[0,2]\n",
        "                R[2,1] = R[1,2]\n",
        "                group = dist.new_group(range(self.world_size))\n",
        "                dist.all_reduce(R, op=dist.ReduceOp.SUM, group=group)\n",
        "                eigenvalues, eigenvectors = torch.linalg.eigh(R)\n",
        "                self.params[a, b] = eigenvectors[:, torch.argmax(eigenvalues)]\n",
        "                if dist.get_rank() == 0: \n",
        "                    print(torch.max(eigenvalues))\n",
        "    def eval(self, train, test):\n",
        "        group = dist.new_group(range(self.world_size))\n",
        "        cri = torch.zeros(4)\n",
        "        train_feat, train_label = train\n",
        "        test_feat, test_label = test\n",
        "        train_size = train_label.shape[0]\n",
        "        test_size = test_label.shape[0]\n",
        "        for a in range(test_size):\n",
        "            # x = amplitude_embedding(test_feat[a], 6, self.n_qubits)\n",
        "            x = torch.eye(2**self.n_qubits).to(torch.complex64)\n",
        "            for b in range(self.layer_size):\n",
        "                x = frax_embedding(test_feat[a], 6, self.n_qubits) @ x\n",
        "                x = Frax_ansatz(self.n_qubits, self.params[b]) @ x\n",
        "            x = x[:,0]\n",
        "            if converter[test_label[a]][0] * bit_Z(x,1) > 0 and converter[test_label[a]][1] * bit_Z(x,6) > 0:# and converter[test_label[a]][2] * bit_Z(x[a],5) > 0:\n",
        "                cri[0] += 1\n",
        "            cri[1] += converter[test_label[a]][0] * bit_Z(x, 1) + converter[test_label[a]][1] * bit_Z(x, 6)# + converter[test_label[a]][2] * bit_Z(x[a], 5)\n",
        "        for a in range(train_size):\n",
        "            # x = amplitude_embedding(train_feat[a], 6, self.n_qubits)\n",
        "            x = torch.eye(2**self.n_qubits).to(torch.complex64)\n",
        "            for b in range(self.layer_size):\n",
        "                x = frax_embedding(train_feat[a], 6, self.n_qubits) @ x\n",
        "                x = Frax_ansatz(self.n_qubits, self.params[b]) @ x\n",
        "            x = x[:,0]\n",
        "            if converter[train_label[a]][0] * bit_Z(x,1) > 0 and converter[train_label[a]][1] * bit_Z(x,6) > 0:# and converter[train_label[a]][2] * bit_Z(x[a],5) > 0:\n",
        "                cri[2] += 1\n",
        "            cri[3] += converter[train_label[a]][0] * bit_Z(x, 1) + converter[train_label[a]][1] * bit_Z(x, 6)# + converter[train_label[a]][2] * bit_Z(x[a], 5)\n",
        "        dist.all_reduce(cri, op=dist.ReduceOp.SUM, group=group)\n",
        "        return (cri[0], 2*cri[1]), (cri[2], 2*cri[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ImeFBrSJXNim"
      },
      "outputs": [],
      "source": [
        "W = 4 # World_size\n",
        "L = 1 # Layer_size\n",
        "N = 5 # Iteration_size\n",
        "Q = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2eFvABAXOEF",
        "outputId": "d8d9fad5-4356-4a80-c47b-49b9a07c5d49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am  2\n",
            "I am  I am I am   310\n",
            "\n",
            "\n",
            "tensor(-1198.9880)\n",
            "tensor(-1198.9885)\n",
            "tensor(-1198.9883)\n",
            "tensor(-1198.9885)\n",
            "tensor(-1198.9883)\n",
            "tensor(-1140.5768)\n",
            "tensor(0.2663) tensor(0.2250) tensor(-1140.5768) tensor(-913.8596)\n",
            "tensor(-1140.5769)\n",
            "tensor(-1140.5768)\n",
            "tensor(-1140.5770)\n",
            "tensor(-1140.5764)\n",
            "tensor(-1140.5765)\n",
            "tensor(-1140.5769)\n",
            "tensor(0.2663) tensor(0.2250) tensor(-1140.5778) tensor(-913.8597)\n",
            "tensor(-1140.5767)\n",
            "tensor(-1140.5763)\n",
            "tensor(-1140.5760)\n",
            "tensor(-1140.5763)\n",
            "tensor(-1140.5764)\n",
            "tensor(-1140.5769)\n",
            "tensor(0.2663) tensor(0.2250) tensor(-1140.5771) tensor(-913.8600)\n",
            "tensor(-1140.5771)\n",
            "tensor(-1140.5764)\n",
            "tensor(-1140.5764)\n",
            "tensor(-1140.5769)\n",
            "tensor(-1140.5771)\n",
            "tensor(-1140.5769)\n",
            "tensor(0.2663) tensor(0.2250) tensor(-1140.5773) tensor(-913.8597)\n",
            "tensor(-1140.5770)\n",
            "tensor(-1140.5773)\n",
            "tensor(-1140.5771)\n",
            "tensor(-1140.5768)\n",
            "tensor(-1140.5769)\n",
            "tensor(-1140.5771)\n",
            "tensor(0.2663) tensor(0.2250) tensor(-1140.5773) tensor(-913.8596)\n",
            "Implementation time :  513.9678840637207\n"
          ]
        }
      ],
      "source": [
        "processes = []\n",
        "st = time.time()\n",
        "for rank in range(W):\n",
        "    p = mp.Process(target=init_process, args=(rank, W, L, N, Q, parallel_train))\n",
        "    p.start()\n",
        "    processes.append(p)\n",
        "        \n",
        "for p in processes:\n",
        "    p.join()\n",
        "        \n",
        "print('Implementation time : ', time.time()-st)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPAOW3v-jorS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "mount_file_id": "1itw76wfUr8rViiHGGXumni5gI-vy2ebE",
      "authorship_tag": "ABX9TyOo3+B+OG7hi3/j7HMwG1x/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}